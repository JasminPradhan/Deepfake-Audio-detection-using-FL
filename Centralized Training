{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10850836,"sourceType":"datasetVersion","datasetId":6739209},{"sourceId":11262331,"sourceType":"datasetVersion","datasetId":7039231}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import and Install Dependancies","metadata":{}},{"cell_type":"code","source":"!pip install torch torchaudio transformers datasets scikit-learn soundfile torchvision audiomentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:54:22.340245Z","iopub.execute_input":"2025-04-12T16:54:22.340422Z","iopub.status.idle":"2025-04-12T16:55:45.238305Z","shell.execute_reply.started":"2025-04-12T16:54:22.340404Z","shell.execute_reply":"2025-04-12T16:55:45.237304Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nCollecting audiomentations\n  Downloading audiomentations-0.40.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec (from torch)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nCollecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n  Downloading numpy_minmax-0.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting numpy-rms<1,>=0.4.2 (from audiomentations)\n  Downloading numpy_rms-0.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations) (0.10.2.post1)\nCollecting python-stretch<1,>=0.3.1 (from audiomentations)\n  Downloading python_stretch-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nRequirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations) (0.5.0.post1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nINFO: pip is looking at multiple versions of numpy-minmax to determine which version is compatible with other requirements. This could take a while.\nCollecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n  Downloading numpy_minmax-0.3.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nINFO: pip is looking at multiple versions of numpy-rms to determine which version is compatible with other requirements. This could take a while.\nCollecting numpy-rms<1,>=0.4.2 (from audiomentations)\n  Downloading numpy_rms-0.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.3.7)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading audiomentations-0.40.0-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy_minmax-0.3.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\nDownloading numpy_rms-0.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17 kB)\nDownloading python_stretch-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-stretch, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, numpy-rms, numpy-minmax, audiomentations\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed audiomentations-0.40.0 fsspec-2024.12.0 numpy-minmax-0.3.1 numpy-rms-0.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-stretch-0.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchaudio\nfrom transformers import HubertModel\nimport os\nimport glob\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:56:08.090504Z","iopub.execute_input":"2025-04-12T16:56:08.090833Z","iopub.status.idle":"2025-04-12T16:56:35.350948Z","shell.execute_reply.started":"2025-04-12T16:56:08.090804Z","shell.execute_reply":"2025-04-12T16:56:35.350032Z"}},"outputs":[{"name":"stderr","text":"2025-04-12 16:56:22.550906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744476982.759318      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744476982.820807      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Declare Values","metadata":{}},{"cell_type":"code","source":"class Config:\n    def __init__(self):\n        self.datasets = {\n            # \"fake92\": \"/kaggle/input/imbalanceddataset/fake92\",\n            # \"real90\": \"/kaggle/input/imbalanceddataset/real90\", \n            # \"balanced\": \"/kaggle/input/fakes-and-reals/audio_train/audio_train\"\n        }\n        self.test_path = \"/kaggle/input/fakes-and-reals/audio_test/audio_test\"\n        \n        # Hardware settings\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.num_workers = 4\n        self.pin_memory = True\n        \n        # Training parameters\n        self.num_epochs = 20\n        self.batch_size = 8\n        self.train_val_split = 0.8\n        \n        # Audio processing\n        self.sample_rate = 16000\n        self.max_length = 16000\n        self.label_mapping = {\"real\": 0, \"fake\": 1}  # Simplified mapping\n        \n        # Model configuration\n        self.unfreeze_layers = [-1]  # Last layer only\n        self.use_augmentation = True\n        \n        # Optimization parameters\n        self.base_lr = 1e-5\n        self.classifier_lr_multiplier = 5\n        self.lr_decay_per_epoch = 0.95\n        self.min_lr = 1e-7\n        self.huber_weight_decay = 1e-5\n        self.classifier_weight_decay = 1e-4\n        self.gradient_clip = 1.0\n\nconfig = Config()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:58:02.426058Z","iopub.execute_input":"2025-04-12T16:58:02.427089Z","iopub.status.idle":"2025-04-12T16:58:02.433845Z","shell.execute_reply.started":"2025-04-12T16:58:02.427055Z","shell.execute_reply":"2025-04-12T16:58:02.432866Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"results = {\n    'metrics': {},\n    'curves': {}\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:58:05.789873Z","iopub.execute_input":"2025-04-12T16:58:05.790349Z","iopub.status.idle":"2025-04-12T16:58:05.793969Z","shell.execute_reply.started":"2025-04-12T16:58:05.790325Z","shell.execute_reply":"2025-04-12T16:58:05.793423Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Prepare Audio Dataset","metadata":{}},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, root_dir, config, augment=False):\n        self.config = config\n        self.file_list = []\n        self.labels = []\n        self.augment = augment\n        self._load_data(root_dir)\n\n    def _is_valid_audio(self, file_path):\n        \"\"\"Enhanced validation with detailed logging\"\"\"\n        try:\n            # Check file size\n            if os.path.getsize(file_path) == 0:\n                print(f\"Empty file: {file_path}\")\n                return False\n                \n            # Try loading the file\n            waveform, sr = torchaudio.load(file_path)\n            if waveform.nelement() == 0:\n                return False\n            if waveform.shape[0] not in [1, 2]:  # Mono or stereo\n                return False\n            if waveform.shape[1] < 100:  # Minimum 100 samples\n                print(f\"Short audio: {file_path} ({waveform.shape[1]} samples)\")\n                return False\n            return True\n        except Exception as e:\n            print(f\"Error loading {file_path}: {str(e)}\")\n            return False\n\n    def _load_data(self, root_dir):\n        for label_name in self.config.label_mapping:\n            label = self.config.label_mapping[label_name]\n            folder = os.path.join(root_dir, label_name)\n            \n            if not os.path.exists(folder):\n                print(f\"Warning: Missing directory {folder}\")\n                continue\n                \n            files = glob.glob(os.path.join(folder, \"*.*\"))\n            print(f\"Found {len(files)} files in {folder}\")\n            \n            for file in files:\n                if self._is_valid_audio(file):\n                    self.file_list.append(file)\n                    self.labels.append(label)\n                else:\n                    print(f\"Warning: Skipping invalid file: {file}\")\n            \n\n        # Shuffle dataset\n        random.seed(42)\n        combined = list(zip(self.file_list, self.labels))\n        random.shuffle(combined)\n        self.file_list, self.labels = zip(*combined) if combined else ([], [])\n\n    def __getitem__(self, idx):\n        try:\n            waveform, sr = torchaudio.load(self.file_list[idx])\n            \n            # Resample if needed\n            if sr != self.config.sample_rate:\n                resampler = torchaudio.transforms.Resample(sr, self.config.sample_rate)\n                waveform = resampler(waveform)\n\n            # Process waveform\n            waveform = self._process_waveform(waveform)\n            return waveform, self.labels[idx]\n            \n        except Exception as e:\n            print(f\"Error loading {self.file_list[idx]}: {str(e)}\")\n            return torch.zeros((1, self.config.max_length)), 0\n\n    def _process_waveform(self, waveform):\n        # Convert to mono\n        if waveform.shape[0] > 1:\n            waveform = waveform.mean(dim=0, keepdim=True)\n            \n        # Trim/pad to fixed length\n        if waveform.shape[1] > self.config.max_length:\n            waveform = waveform[:, :self.config.max_length]\n        else:\n            pad_amount = self.config.max_length - waveform.shape[1]\n            waveform = torch.nn.functional.pad(waveform, (0, pad_amount))\n            \n        return waveform\n\n    def __len__(self):\n        return len(self.file_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:58:18.050726Z","iopub.execute_input":"2025-04-12T16:58:18.051298Z","iopub.status.idle":"2025-04-12T16:58:18.063941Z","shell.execute_reply.started":"2025-04-12T16:58:18.051268Z","shell.execute_reply":"2025-04-12T16:58:18.063004Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def collate_fn(batch):\n    waveforms, labels = [], []\n    for wav, lbl in batch:\n        waveforms.append(wav)\n        labels.append(lbl)\n    return torch.stack(waveforms), torch.tensor(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:58:47.881119Z","iopub.execute_input":"2025-04-12T16:58:47.881966Z","iopub.status.idle":"2025-04-12T16:58:47.886918Z","shell.execute_reply.started":"2025-04-12T16:58:47.881930Z","shell.execute_reply":"2025-04-12T16:58:47.886039Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# HuBERT Classifier","metadata":{}},{"cell_type":"code","source":"class HuBERTClassifier(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.hubert = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n        self._freeze_layers()\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, len(config.label_mapping))\n        )\n    \n    def _freeze_layers(self):\n        for idx, layer in enumerate(self.hubert.encoder.layers):\n            layer.requires_grad_(idx in config.unfreeze_layers)\n\n    def forward(self, x):\n        if x.dim() == 3:  # Handle channel dimension\n            x = x.squeeze(1)\n        outputs = self.hubert(x)\n        features = outputs.last_hidden_state.mean(dim=1)\n        return self.classifier(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:58:50.375966Z","iopub.execute_input":"2025-04-12T16:58:50.376670Z","iopub.status.idle":"2025-04-12T16:58:50.382321Z","shell.execute_reply.started":"2025-04-12T16:58:50.376632Z","shell.execute_reply":"2025-04-12T16:58:50.381600Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"test_dataset = AudioDataset(config.test_path, config)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n                         collate_fn=collate_fn, pin_memory=config.pin_memory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T16:59:01.450666Z","iopub.execute_input":"2025-04-12T16:59:01.451393Z","iopub.status.idle":"2025-04-12T17:00:16.942761Z","shell.execute_reply.started":"2025-04-12T16:59:01.451359Z","shell.execute_reply":"2025-04-12T17:00:16.941835Z"}},"outputs":[{"name":"stdout","text":"Found 2500 files in /kaggle/input/fakes-and-reals/audio_test/audio_test/real\nFound 2500 files in /kaggle/input/fakes-and-reals/audio_test/audio_test/fake\nEmpty file: /kaggle/input/fakes-and-reals/audio_test/audio_test/fake/file32972.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_test/audio_test/fake/file32972.mp3\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Add to top imports\nimport csv\nfrom datetime import datetime\nimport json\n\nclass DiskMetricWriter:\n    def __init__(self):\n        self.output_dir = \"/kaggle/working/metrics\"\n        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        os.makedirs(self.output_dir, exist_ok=True)\n        \n    def _get_path(self, dataset_name, metric_type):\n        return f\"{self.output_dir}/{dataset_name}_{self.timestamp}_{metric_type}.csv\"\n\n    def write_epoch_metrics(self, dataset_name, epoch, train_loss, val_loss, train_acc, val_acc):\n        path = self._get_path(dataset_name, \"training\")\n        write_header = not os.path.exists(path)\n        \n        with open(path, 'a', newline='') as f:\n            writer = csv.writer(f)\n            if write_header:\n                writer.writerow(['epoch', 'train_loss', 'val_loss', 'train_acc', 'val_acc'])\n            writer.writerow([epoch, train_loss, val_loss, train_acc, val_acc])\n\n    def write_final_metrics(self, dataset_name, test_loss, test_acc, auc_score):\n        path = self._get_path(dataset_name, \"final\")\n        with open(path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['metric', 'value'])\n            writer.writerow(['test_loss', test_loss])\n            writer.writerow(['test_accuracy', test_acc])\n            writer.writerow(['auc', auc_score])\n\n    def write_confusion_matrix(self, dataset_name, cm, classes):\n        path = self._get_path(dataset_name, \"confusion\")\n        with open(path, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow([''] + list(classes))\n            for i, row in enumerate(cm):\n                writer.writerow([classes[i]] + list(row))\n\n    def write_classification_report(self, dataset_name, report):\n        path = self._get_path(dataset_name, \"classification\").replace('.csv', '.txt')\n        with open(path, 'w') as f:\n            f.write(report)\n\n    \n    def save_test_predictions(self, dataset_name, probs, labels):\n        probs_path = f\"{self.output_dir}/{dataset_name}_{self.timestamp}_probs.npy\"\n        labels_path = f\"{self.output_dir}/{dataset_name}_{self.timestamp}_labels.npy\"\n        np.save(probs_path, probs)\n        np.save(labels_path, labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T17:04:55.420013Z","iopub.execute_input":"2025-04-12T17:04:55.420282Z","iopub.status.idle":"2025-04-12T17:04:55.430506Z","shell.execute_reply.started":"2025-04-12T17:04:55.420263Z","shell.execute_reply":"2025-04-12T17:04:55.429749Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Metrics Saving and Visualisation","metadata":{}},{"cell_type":"code","source":"class TestVisualizer:\n    def __init__(self):\n        self.output_dir = \"/kaggle/working/test_metrics\"\n        os.makedirs(self.output_dir, exist_ok=True)\n        self.metrics = []\n\n    def add_metrics(self, dataset_name, test_metrics, fpr, tpr, auc_score, cm):\n        self.metrics.append({\n            'dataset': dataset_name,\n            'accuracy': test_metrics['accuracy'],\n            'loss': test_metrics['loss'],\n            'auc': auc_score,\n            'fpr': fpr,\n            'tpr': tpr,\n            'cm': cm\n        })\n\n    def save_metrics_to_csv(self):\n        df = pd.DataFrame([{\n            'dataset': m['dataset'],\n            'accuracy': m['accuracy'],\n            'loss': m['loss'],\n            'auc': m['auc']\n        } for m in self.metrics])\n        df.to_csv(f\"{self.output_dir}/test_metrics_summary.csv\", index=False)\n\n    def plot_all(self):\n        plt.figure(figsize=(20, 15))\n        \n        # 1. AUC-ROC Curves\n        plt.subplot(2, 2, 1)\n        for m in self.metrics:\n            plt.plot(m['fpr'], m['tpr'], label=f\"{m['dataset']} (AUC = {m['auc']:.2f})\")\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curves Comparison')\n        plt.legend()\n        \n        # 2. Accuracy Comparison\n        plt.subplot(2, 2, 2)\n        accuracies = [m['accuracy'] for m in self.metrics]\n        plt.bar(range(len(self.metrics)), accuracies)\n        plt.xticks(range(len(self.metrics)), [m['dataset'] for m in self.metrics])\n        plt.ylim(0, 1)\n        plt.ylabel('Accuracy')\n        plt.title('Test Accuracy Comparison')\n        \n        # 3. Loss Comparison\n        plt.subplot(2, 2, 3)\n        losses = [m['loss'] for m in self.metrics]\n        plt.bar(range(len(self.metrics)), losses)\n        plt.xticks(range(len(self.metrics)), [m['dataset'] for m in self.metrics])\n        plt.ylabel('Loss')\n        plt.title('Test Loss Comparison')\n        \n        # 4. Confusion Matrices\n        plt.subplot(2, 2, 4)\n        for idx, m in enumerate(self.metrics):\n            plt.subplot(2, 2, 4)\n            sns.heatmap(m['cm'], annot=True, fmt='d', \n                        xticklabels=['Real', 'Fake'], \n                        yticklabels=['Real', 'Fake'])\n            plt.title(f'Confusion Matrix - {m[\"dataset\"]}')\n            plt.ylabel('True Label')\n            plt.xlabel('Predicted Label')\n            plt.savefig(f\"{self.output_dir}/confusion_matrix_{m['dataset']}.png\")\n            plt.clf()\n        \n        plt.tight_layout()\n        plt.savefig(f\"{self.output_dir}/test_performance_summary.png\")\n        plt.close()\n\n# Initialize visualizer\ntest_visualizer = TestVisualizer()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T17:05:27.965646Z","iopub.execute_input":"2025-04-12T17:05:27.965960Z","iopub.status.idle":"2025-04-12T17:05:27.977243Z","shell.execute_reply.started":"2025-04-12T17:05:27.965940Z","shell.execute_reply":"2025-04-12T17:05:27.976356Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"metric_writer = DiskMetricWriter()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T17:05:30.899875Z","iopub.execute_input":"2025-04-12T17:05:30.900659Z","iopub.status.idle":"2025-04-12T17:05:30.904419Z","shell.execute_reply.started":"2025-04-12T17:05:30.900630Z","shell.execute_reply":"2025-04-12T17:05:30.903576Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, loader, device, criterion=None):\n    \"\"\"Enhanced evaluation function with all metrics\"\"\"\n    model.eval()\n    all_labels = []\n    all_preds = []\n    all_probs = []\n    total_loss = 0.0\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            \n            # Calculate loss if criterion provided\n            if criterion:\n                loss = criterion(outputs, labels)\n                total_loss += loss.item()\n            \n            probs = torch.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    metrics = {\n        'labels': np.array(all_labels),\n        'preds': np.array(all_preds),\n        'probs': np.array(all_probs)\n    }\n    \n    if criterion:\n        metrics['loss'] = total_loss / len(loader)\n        metrics['accuracy'] = np.mean(metrics['labels'] == metrics['preds'])\n    \n    return metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T17:05:33.730292Z","iopub.execute_input":"2025-04-12T17:05:33.731178Z","iopub.status.idle":"2025-04-12T17:05:33.741588Z","shell.execute_reply.started":"2025-04-12T17:05:33.731141Z","shell.execute_reply":"2025-04-12T17:05:33.740786Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Training and evaluation loop for each dataset\nfor dataset_name, train_path in config.datasets.items():\n    print(f\"\\n{'='*40}\")\n    print(f\"Training on {dataset_name}\")\n    print(f\"{'='*40}\")\n    \n    # Initialize fresh model\n    model = HuBERTClassifier(config).to(config.device)\n    criterion = nn.CrossEntropyLoss()  # Fixed typo\n    optimizer = optim.Adam([\n        {'params': model.hubert.parameters(), 'lr': config.base_lr},\n        {'params': model.classifier.parameters(), \n         'lr': config.base_lr * config.classifier_lr_multiplier}\n    ])\n    \n    # Create datasets\n    train_dataset = AudioDataset(train_path, config, augment=True)\n    train_size = int(config.train_val_split * len(train_dataset))\n    train_dataset, val_dataset = random_split(train_dataset, [train_size, len(train_dataset)-train_size])\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n                            shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n                          collate_fn=collate_fn)\n    \n    best_val_acc = 0.0\n    \n    # Single epoch loop\n    for epoch in range(config.num_epochs):\n        model.train()\n        epoch_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Training\n        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            inputs, labels = inputs.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(config.device), labels.to(config.device)\n                outputs = model(inputs)\n                val_loss += criterion(outputs, labels).item()\n                \n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n        \n        # Calculate metrics\n        train_loss = epoch_loss / len(train_loader)\n        train_acc = correct / total\n        val_loss = val_loss / len(val_loader)\n        val_acc = val_correct / val_total\n        \n        # Write to disk immediately\n        metric_writer.write_epoch_metrics(\n            dataset_name=dataset_name,\n            epoch=epoch+1,\n            train_loss=train_loss,\n            val_loss=val_loss,\n            train_acc=train_acc,\n            val_acc=val_acc\n        )\n        \n        # Update learning rate\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = max(param_group['lr'] * config.lr_decay_per_epoch, \n                                  config.min_lr)\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), f\"best_model_{dataset_name}.pth\")\n        \n        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2%}\")\n        print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2%}\\n\")\n    \n    # Final test evaluation\n    test_metrics = evaluate_model(model, test_loader, config.device, criterion)\n\n\n    metric_writer.save_test_predictions(\n        dataset_name=dataset_name,\n        probs=test_metrics['probs'],\n        labels=test_metrics['labels']\n    )\n    \n    # Final test evaluation\n    test_metrics = evaluate_model(model, test_loader, config.device, criterion)\n    \n    # Calculate metrics\n    fpr, tpr, _ = roc_curve(test_metrics['labels'], test_metrics['probs'][:, 1])\n    auc_score = auc(fpr, tpr)\n    cm = confusion_matrix(test_metrics['labels'], np.argmax(test_metrics['probs'], axis=1))\n    \n    # Store metrics for visualization\n    test_visualizer.add_metrics(dataset_name, test_metrics, fpr, tpr, auc_score, cm)\n    \n    metric_writer.write_final_metrics(\n        dataset_name=dataset_name,\n        test_loss=test_metrics['loss'],\n        test_acc=test_metrics['accuracy'],\n        auc_score=auc_score\n    )\n    \n    # Cleanup\n    del model, criterion, optimizer, train_dataset, val_dataset\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T17:05:39.566738Z","iopub.execute_input":"2025-04-12T17:05:39.567065Z","iopub.status.idle":"2025-04-12T20:25:27.809178Z","shell.execute_reply.started":"2025-04-12T17:05:39.567042Z","shell.execute_reply":"2025-04-12T20:25:27.808492Z"}},"outputs":[{"name":"stdout","text":"\n========================================\nTraining on balanced\n========================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b9fb840baf4407187a800623d7ab6cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aae6209fe934b6bb3ce1b44fddf16c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb331b502a67491881c9bc9c704cbf17"}},"metadata":{}},{"name":"stdout","text":"Found 15000 files in /kaggle/input/fakes-and-reals/audio_train/audio_train/real\nFound 15000 files in /kaggle/input/fakes-and-reals/audio_train/audio_train/fake\nError loading /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file31017.mp3: Failed to open the input \"/kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file31017.mp3\" (Invalid argument).\nException raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7e096d8b9446 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7e096d8636e4 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x42134 (0x7e091e488134 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x7e091e48ab34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\nframe #4: <unknown function> + 0x3a8de (0x7e0885b718de in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #5: <unknown function> + 0x323ee (0x7e0885b693ee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\nframe #6: /usr/bin/python3() [0x55559b]\nframe #7: _PyObject_MakeTpCall + 0x27c (0x52f67c in /usr/bin/python3)\nframe #8: /usr/bin/python3() [0x58536d]\nframe #9: /usr/bin/python3() [0x56e229]\nframe #10: /usr/bin/python3() [0x52fa60]\nframe #11: <unknown function> + 0xfc8b (0x7e096c083c8b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\nframe #12: _PyObject_MakeTpCall + 0x27c (0x52f67c in /usr/bin/python3)\nframe #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d7ff in /usr/bin/python3)\nframe #14: _PyFunction_Vectorcall + 0x173 (0x5661a3 in /usr/bin/python3)\nframe #15: /usr/bin/python3() [0x56deb6]\nframe #16: _PyObject_MakeTpCall + 0x23b (0x52f63b in /usr/bin/python3)\nframe #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d7ff in /usr/bin/python3)\nframe #18: _PyFunction_Vectorcall + 0x173 (0x5661a3 in /usr/bin/python3)\nframe #19: /usr/bin/python3() [0x56df52]\nframe #20: _PyObject_MakeTpCall + 0x23b (0x52f63b in /usr/bin/python3)\nframe #21: _PyEval_EvalFrameDefault + 0x6bf (0x53d7ff in /usr/bin/python3)\nframe #22: /usr/bin/python3() [0x6135e4]\nframe #23: PyEval_EvalCode + 0x97 (0x612c47 in /usr/bin/python3)\nframe #24: /usr/bin/python3() [0x62ca33]\nframe #25: _PyEval_EvalFrameDefault + 0x390f (0x540a4f in /usr/bin/python3)\nframe #26: /usr/bin/python3() [0x6284b0]\nframe #27: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #28: /usr/bin/python3() [0x6284b0]\nframe #29: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #30: /usr/bin/python3() [0x6284b0]\nframe #31: /usr/bin/python3() [0x62aaec]\nframe #32: _PyEval_EvalFrameDefault + 0x3a9d (0x540bdd in /usr/bin/python3)\nframe #33: /usr/bin/python3() [0x585a87]\nframe #34: /usr/bin/python3() [0x58526e]\nframe #35: PyObject_Call + 0xf4 (0x570704 in /usr/bin/python3)\nframe #36: _PyEval_EvalFrameDefault + 0x4a8f (0x541bcf in /usr/bin/python3)\nframe #37: /usr/bin/python3() [0x6284b0]\nframe #38: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #39: /usr/bin/python3() [0x6284b0]\nframe #40: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #41: /usr/bin/python3() [0x6284b0]\nframe #42: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #43: /usr/bin/python3() [0x6284b0]\nframe #44: _PyEval_EvalFrameDefault + 0x3485 (0x5405c5 in /usr/bin/python3)\nframe #45: /usr/bin/python3() [0x6284b0]\nframe #46: <unknown function> + 0x745f (0x7e09a674745f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\nframe #47: /usr/bin/python3() [0x553a1f]\nframe #48: /usr/bin/python3() [0x4d0bc0]\nframe #49: /usr/bin/python3() [0x4e94f3]\nframe #50: /usr/bin/python3() [0x54b25b]\nframe #51: _PyEval_EvalFrameDefault + 0x9129 (0x546269 in /usr/bin/python3)\nframe #52: /usr/bin/python3() [0x6135e4]\nframe #53: PyEval_EvalCode + 0x97 (0x612c47 in /usr/bin/python3)\nframe #54: /usr/bin/python3() [0x62ca33]\nframe #55: /usr/bin/python3() [0x54b25b]\nframe #56: PyObject_Vectorcall + 0x35 (0x54b145 in /usr/bin/python3)\nframe #57: _PyEval_EvalFrameDefault + 0x6bf (0x53d7ff in /usr/bin/python3)\nframe #58: _PyFunction_Vectorcall + 0x173 (0x5661a3 in /usr/bin/python3)\nframe #59: /usr/bin/python3() [0x63e860]\nframe #60: Py_RunMain + 0x13c (0x63e1bc in /usr/bin/python3)\nframe #61: Py_BytesMain + 0x2d (0x603f2d in /usr/bin/python3)\nframe #62: <unknown function> + 0x29d90 (0x7e09a7e46d90 in /lib/x86_64-linux-gnu/libc.so.6)\n\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file31017.mp3\nEmpty file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27839.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27839.mp3\nEmpty file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27643.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27643.mp3\nEmpty file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27206.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file27206.mp3\nEmpty file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file30959.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_train/audio_train/fake/file30959.mp3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 3000/3000 [08:31<00:00,  5.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\nTrain Loss: 0.2289 | Acc: 92.11%\nVal Loss: 0.1117 | Acc: 96.35%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 3000/3000 [08:32<00:00,  5.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20\nTrain Loss: 0.0868 | Acc: 98.00%\nVal Loss: 0.0581 | Acc: 98.45%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 3000/3000 [08:14<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20\nTrain Loss: 0.0648 | Acc: 98.60%\nVal Loss: 0.0606 | Acc: 98.52%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 3000/3000 [08:11<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20\nTrain Loss: 0.0577 | Acc: 98.85%\nVal Loss: 0.0527 | Acc: 98.70%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 3000/3000 [08:20<00:00,  6.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20\nTrain Loss: 0.0457 | Acc: 99.10%\nVal Loss: 0.0555 | Acc: 98.80%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 3000/3000 [08:00<00:00,  6.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20\nTrain Loss: 0.0406 | Acc: 99.19%\nVal Loss: 0.0466 | Acc: 99.00%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 3000/3000 [07:58<00:00,  6.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20\nTrain Loss: 0.0366 | Acc: 99.30%\nVal Loss: 0.0398 | Acc: 99.17%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 3000/3000 [08:02<00:00,  6.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20\nTrain Loss: 0.0326 | Acc: 99.40%\nVal Loss: 0.0374 | Acc: 99.10%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 3000/3000 [07:54<00:00,  6.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20\nTrain Loss: 0.0311 | Acc: 99.37%\nVal Loss: 0.0335 | Acc: 99.25%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 3000/3000 [07:56<00:00,  6.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20\nTrain Loss: 0.0245 | Acc: 99.54%\nVal Loss: 0.0348 | Acc: 99.22%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 3000/3000 [07:58<00:00,  6.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20\nTrain Loss: 0.0225 | Acc: 99.57%\nVal Loss: 0.0315 | Acc: 99.20%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 3000/3000 [08:37<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20\nTrain Loss: 0.0233 | Acc: 99.58%\nVal Loss: 0.0324 | Acc: 99.30%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 3000/3000 [08:01<00:00,  6.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20\nTrain Loss: 0.0194 | Acc: 99.62%\nVal Loss: 0.0283 | Acc: 99.37%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 3000/3000 [08:22<00:00,  5.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20\nTrain Loss: 0.0247 | Acc: 99.59%\nVal Loss: 0.0243 | Acc: 99.43%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 3000/3000 [08:32<00:00,  5.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20\nTrain Loss: 0.0170 | Acc: 99.68%\nVal Loss: 0.0312 | Acc: 99.30%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 3000/3000 [08:10<00:00,  6.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20\nTrain Loss: 0.0154 | Acc: 99.70%\nVal Loss: 0.0257 | Acc: 99.38%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 3000/3000 [08:10<00:00,  6.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20\nTrain Loss: 0.0152 | Acc: 99.74%\nVal Loss: 0.0297 | Acc: 99.40%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 3000/3000 [08:04<00:00,  6.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20\nTrain Loss: 0.0113 | Acc: 99.74%\nVal Loss: 0.0307 | Acc: 99.43%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 3000/3000 [08:33<00:00,  5.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20\nTrain Loss: 0.0110 | Acc: 99.82%\nVal Loss: 0.0280 | Acc: 99.50%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 3000/3000 [08:23<00:00,  5.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20\nTrain Loss: 0.0144 | Acc: 99.77%\nVal Loss: 0.0242 | Acc: 99.55%\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# After all datasets are processed\ntest_visualizer.save_metrics_to_csv()\ntest_visualizer.plot_all()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:25:43.394111Z","iopub.execute_input":"2025-04-12T20:25:43.394670Z","iopub.status.idle":"2025-04-12T20:25:44.403391Z","shell.execute_reply.started":"2025-04-12T20:25:43.394634Z","shell.execute_reply":"2025-04-12T20:25:44.402384Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def plot_comparative_curves(metric_dir=\"/kaggle/working/metrics\"):\n    import os\n    import glob\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.metrics import roc_curve\n    \n    # Create directory if not exists\n    os.makedirs(metric_dir, exist_ok=True)\n    \n    # Get all dataset names from config\n    datasets = list(config.datasets.keys())\n    \n    plt.figure(figsize=(15, 10))\n    \n    # 1. Loss Comparison\n    plt.subplot(2, 2, 1)\n    for dataset in datasets:\n        try:\n            # Find latest training file for this dataset\n            train_files = glob.glob(f\"{metric_dir}/{dataset}_*_training.csv\")\n            if not train_files:\n                print(f\"No training files found for {dataset}, skipping\")\n                continue\n                \n            latest_file = max(train_files, key=os.path.getctime)\n            df = pd.read_csv(latest_file)\n            \n            plt.plot(df['epoch'], df['train_loss'], label=f'{dataset} Train')\n            plt.plot(df['epoch'], df['val_loss'], '--', label=f'{dataset} Val')\n        except Exception as e:\n            print(f\"Error plotting {dataset} loss: {str(e)}\")\n            continue\n\n    plt.title('Loss Comparison')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # 2. Accuracy Comparison\n    plt.subplot(2, 2, 2)\n    for dataset in datasets:\n        try:\n            train_files = glob.glob(f\"{metric_dir}/{dataset}_*_training.csv\")\n            if not train_files:\n                continue\n                \n            latest_file = max(train_files, key=os.path.getctime)\n            df = pd.read_csv(latest_file)\n            \n            plt.plot(df['epoch'], df['train_acc'], label=f'{dataset} Train')\n            plt.plot(df['epoch'], df['val_acc'], '--', label=f'{dataset} Val')\n        except Exception as e:\n            print(f\"Error plotting {dataset} accuracy: {str(e)}\")\n            continue\n\n    plt.title('Accuracy Comparison')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # 3. Test Metrics Comparison\n    plt.subplot(2, 2, 3)\n    metrics_list = []\n    for dataset in datasets:\n        try:\n            test_files = glob.glob(f\"{metric_dir}/{dataset}_*_final.csv\")\n            if not test_files:\n                continue\n                \n            latest_test = max(test_files, key=os.path.getctime)\n            df_test = pd.read_csv(latest_test)\n            \n            accuracy_value = df_test.loc[df_test['metric'] == 'test_accuracy', 'value'].values[0]\n            loss_value = df_test.loc[df_test['metric'] == 'test_loss', 'value'].values[0]\n            \n            metrics_list.append({\n                'dataset': dataset,\n                'accuracy': accuracy_value,\n                'loss': loss_value\n            })\n        except Exception as e:\n            print(f\"Error loading test metrics for {dataset}: {str(e)}\")\n            continue\n\n    if metrics_list:\n        metrics_df = pd.DataFrame(metrics_list)\n        x = np.arange(len(metrics_df))\n        width = 0.35\n        \n        plt.bar(x - width/2, metrics_df['accuracy'], width, label='Accuracy')\n        plt.bar(x + width/2, metrics_df['loss'], width, label='Loss')\n        plt.xticks(x, metrics_df['dataset'])\n        plt.title('Test Set Performance')\n        plt.legend()\n    \n    # 4. ROC Comparison\n    plt.subplot(2, 2, 4)\n    for dataset in datasets:\n        try:\n            # Get latest test files\n            test_files = glob.glob(f\"{metric_dir}/{dataset}_*_final.csv\")\n            prob_files = glob.glob(f\"{metric_dir}/{dataset}_*_probs.npy\")\n            label_files = glob.glob(f\"{metric_dir}/{dataset}_*_labels.npy\")\n            \n            if not test_files or not prob_files or not label_files:\n                continue\n                \n            # Load data\n            latest_test = max(test_files, key=os.path.getctime)\n            latest_probs = max(prob_files, key=os.path.getctime)\n            latest_labels = max(label_files, key=os.path.getctime)\n            \n            df_test = pd.read_csv(latest_test)\n            auc_score = df_test.loc[df_test['metric'] == 'auc', 'value'].values[0]\n            probs = np.load(latest_probs)\n            labels = np.load(latest_labels)\n            \n            fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n            plt.plot(fpr, tpr, label=f'{dataset} (AUC = {auc_score:.2f})')\n        except Exception as e:\n            print(f\"Error plotting ROC for {dataset}: {str(e)}\")\n            continue\n\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.title('ROC Curve Comparison')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'{metric_dir}/comparison_plot.png')\n    plt.close()\n    print(f\"Comparison plot saved to {metric_dir}/comparison_plot.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:08.152171Z","iopub.execute_input":"2025-04-12T20:26:08.152782Z","iopub.status.idle":"2025-04-12T20:26:08.174414Z","shell.execute_reply.started":"2025-04-12T20:26:08.152750Z","shell.execute_reply":"2025-04-12T20:26:08.173555Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Generate comparison plots\nplot_comparative_curves()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:16.613106Z","iopub.execute_input":"2025-04-12T20:26:16.613711Z","iopub.status.idle":"2025-04-12T20:26:17.370192Z","shell.execute_reply.started":"2025-04-12T20:26:16.613683Z","shell.execute_reply":"2025-04-12T20:26:17.369491Z"}},"outputs":[{"name":"stdout","text":"Comparison plot saved to /kaggle/working/metrics/comparison_plot.png\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Download Files","metadata":{}},{"cell_type":"code","source":"# zip metrics\n# zip test_metrics\n\n# download link for best_model_{dataset_name}.pth and all metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r metrics.zip /kaggle/working/metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:22.621889Z","iopub.execute_input":"2025-04-12T20:26:22.622158Z","iopub.status.idle":"2025-04-12T20:26:22.836642Z","shell.execute_reply.started":"2025-04-12T20:26:22.622138Z","shell.execute_reply":"2025-04-12T20:26:22.835586Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/metrics/ (stored 0%)\n  adding: kaggle/working/metrics/balanced_20250412_170530_training.csv (deflated 53%)\n  adding: kaggle/working/metrics/balanced_20250412_170530_final.csv (deflated 16%)\n  adding: kaggle/working/metrics/balanced_20250412_170530_labels.npy (deflated 96%)\n  adding: kaggle/working/metrics/balanced_20250412_170530_probs.npy (deflated 32%)\n  adding: kaggle/working/metrics/comparison_plot.png (deflated 13%)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"!zip -r test_metrics.zip /kaggle/working/test-metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:26.097660Z","iopub.execute_input":"2025-04-12T20:26:26.098637Z","iopub.status.idle":"2025-04-12T20:26:26.288700Z","shell.execute_reply.started":"2025-04-12T20:26:26.098601Z","shell.execute_reply":"2025-04-12T20:26:26.287734Z"}},"outputs":[{"name":"stdout","text":"\tzip warning: name not matched: /kaggle/working/test-metrics\n\nzip error: Nothing to do! (try: zip -r test_metrics.zip . -i /kaggle/working/test-metrics)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'best_model_fake92.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:28.807392Z","iopub.execute_input":"2025-04-12T20:26:28.807982Z","iopub.status.idle":"2025-04-12T20:26:28.813933Z","shell.execute_reply.started":"2025-04-12T20:26:28.807951Z","shell.execute_reply":"2025-04-12T20:26:28.813113Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model_fake92.pth","text/html":"Path (<tt>best_model_fake92.pth</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"FileLink(r'best_model_real90.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:32.797633Z","iopub.execute_input":"2025-04-12T20:26:32.797957Z","iopub.status.idle":"2025-04-12T20:26:32.803857Z","shell.execute_reply.started":"2025-04-12T20:26:32.797937Z","shell.execute_reply":"2025-04-12T20:26:32.802939Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model_real90.pth","text/html":"Path (<tt>best_model_real90.pth</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"FileLink(r'best_model_balanced.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:35.243255Z","iopub.execute_input":"2025-04-12T20:26:35.244081Z","iopub.status.idle":"2025-04-12T20:26:35.249099Z","shell.execute_reply.started":"2025-04-12T20:26:35.244054Z","shell.execute_reply":"2025-04-12T20:26:35.248278Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model_balanced.pth","text/html":"<a href='best_model_balanced.pth' target='_blank'>best_model_balanced.pth</a><br>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"FileLink(r'metrics.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T20:26:37.777018Z","iopub.execute_input":"2025-04-12T20:26:37.777806Z","iopub.status.idle":"2025-04-12T20:26:37.783029Z","shell.execute_reply.started":"2025-04-12T20:26:37.777781Z","shell.execute_reply":"2025-04-12T20:26:37.782347Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/metrics.zip","text/html":"<a href='metrics.zip' target='_blank'>metrics.zip</a><br>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"FileLink(r'test_metrics.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}