{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10850836,"sourceType":"datasetVersion","datasetId":6739209},{"sourceId":11262331,"sourceType":"datasetVersion","datasetId":7039231}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install and Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torch torchaudio transformers datasets scikit-learn soundfile torchvision\n!pip install -U ray\n!pip install -U \"flwr[simulation]==1.15.2\"\n!pip install audiomentations optuna opacus ipython","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:53:52.400492Z","iopub.execute_input":"2025-04-07T00:53:52.400712Z","iopub.status.idle":"2025-04-07T00:54:59.423125Z","shell.execute_reply.started":"2025-04-07T00:53:52.400691Z","shell.execute_reply":"2025-04-07T00:54:59.422260Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.42.1)\nCollecting ray\n  Downloading ray-2.44.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.17.0)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.2)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\nRequirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.2)\nRequirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.5.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.22.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2025.1.31)\nDownloading ray-2.44.1-cp310-cp310-manylinux2014_x86_64.whl (67.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ray\n  Attempting uninstall: ray\n    Found existing installation: ray 2.42.1\n    Uninstalling ray-2.42.1:\n      Successfully uninstalled ray-2.42.1\nSuccessfully installed ray-2.44.1\nCollecting flwr==1.15.2 (from flwr[simulation]==1.15.2)\n  Downloading flwr-1.15.2-py3-none-any.whl.metadata (15 kB)\nCollecting cryptography<44.0.0,>=43.0.1 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\nRequirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (1.68.1)\nCollecting iterators<0.0.3,>=0.0.2 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (1.26.4)\nCollecting pathspec<0.13.0,>=0.12.1 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nCollecting protobuf<5.0.0,>=4.21.6 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nRequirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (3.21.0)\nRequirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (6.0.2)\nRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (2.32.3)\nRequirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (13.9.4)\nRequirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr==1.15.2->flwr[simulation]==1.15.2) (2.2.1)\nCollecting tomli-w<2.0.0,>=1.0.0 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting typer<0.13.0,>=0.12.5 (from flwr==1.15.2->flwr[simulation]==1.15.2)\n  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\nCollecting ray==2.31.0 (from flwr[simulation]==1.15.2)\n  Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (8.1.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (3.17.0)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (4.23.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (1.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (24.2)\nRequirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (1.3.2)\nRequirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.31.0->flwr[simulation]==1.15.2) (1.5.0)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->flwr==1.15.2->flwr[simulation]==1.15.2) (1.17.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->flwr==1.15.2->flwr[simulation]==1.15.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->flwr==1.15.2->flwr[simulation]==1.15.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.5.0->flwr==1.15.2->flwr[simulation]==1.15.2) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.5.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.5.0->flwr==1.15.2->flwr[simulation]==1.15.2) (4.12.2)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->flwr==1.15.2->flwr[simulation]==1.15.2) (1.5.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->flwr==1.15.2->flwr[simulation]==1.15.2) (2.22)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr==1.15.2->flwr[simulation]==1.15.2) (0.1.2)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]==1.15.2) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]==1.15.2) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]==1.15.2) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]==1.15.2) (0.22.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.26.0->flwr==1.15.2->flwr[simulation]==1.15.2) (2024.2.0)\nDownloading flwr-1.15.2-py3-none-any.whl (531 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.7/531.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl (66.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\nDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\nDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tomli-w, protobuf, pathspec, iterators, cryptography, typer, ray, flwr\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 44.0.1\n    Uninstalling cryptography-44.0.1:\n      Successfully uninstalled cryptography-44.0.1\n  Attempting uninstall: typer\n    Found existing installation: typer 0.15.1\n    Uninstalling typer-0.15.1:\n      Successfully uninstalled typer-0.15.1\n  Attempting uninstall: ray\n    Found existing installation: ray 2.44.1\n    Uninstalling ray-2.44.1:\n      Successfully uninstalled ray-2.44.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.6 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cryptography-43.0.3 flwr-1.15.2 iterators-0.0.2 pathspec-0.12.1 protobuf-4.25.6 ray-2.31.0 tomli-w-1.2.0 typer-0.12.5\nCollecting audiomentations\n  Downloading audiomentations-0.40.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.1)\nCollecting opacus\n  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\nRequirement already satisfied: numpy<2,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.26.4)\nCollecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n  Downloading numpy_minmax-0.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting numpy-rms<1,>=0.4.2 (from audiomentations)\n  Downloading numpy_rms-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.2.post1)\nCollecting python-stretch<1,>=0.3.1 (from audiomentations)\n  Downloading python_stretch-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nRequirement already satisfied: scipy<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.13.1)\nRequirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.5.0.post1)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.5.1+cu121)\nRequirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.4.0)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\nRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.0->audiomentations) (2.4.1)\nRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\nINFO: pip is looking at multiple versions of numpy-minmax to determine which version is compatible with other requirements. This could take a while.\nCollecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n  Downloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nINFO: pip is looking at multiple versions of numpy-rms to determine which version is compatible with other requirements. This could take a while.\nCollecting numpy-rms<1,>=0.4.2 (from audiomentations)\n  Downloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.3.6)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.0->audiomentations) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.0->audiomentations) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.0->audiomentations) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.0->audiomentations) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.0->audiomentations) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2025.1.31)\nDownloading audiomentations-0.40.0-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opacus-1.5.3-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\nDownloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17 kB)\nDownloading python_stretch-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-stretch, numpy-rms, numpy-minmax, opacus, audiomentations\nSuccessfully installed audiomentations-0.40.0 numpy-minmax-0.3.1 numpy-rms-0.4.2 opacus-1.5.3 python-stretch-0.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport logging\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchaudio\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport flwr as fl\nfrom transformers import HubertModel, HubertConfig\nimport ray","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:54:59.424072Z","iopub.execute_input":"2025-04-07T00:54:59.424288Z","iopub.status.idle":"2025-04-07T00:55:27.068723Z","shell.execute_reply.started":"2025-04-07T00:54:59.424269Z","shell.execute_reply":"2025-04-07T00:55:27.068030Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Setup and Values","metadata":{}},{"cell_type":"code","source":"class Config:\n    def __init__(self):\n        self.dirs = {\n            # \"train\": \"/kaggle/input/imbalanceddataset/real90\",\n            # \"train\": \"/kaggle/input/imbalanceddataset/fake92\", #use it for fake92 \n            # \"train\": \"/kaggle/input/fakes-and-reals/audio_train/audio_train\",# use it for balanced\n            \"test\": \"/kaggle/input/fakes-and-reals/audio_test/audio_test\",\n        }\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.num_clients = 4\n        self.num_rounds = 20\n        self.epochs_per_round = 1\n        self.batch_size = 8\n        self.sample_rate = 16000\n        self.max_length = 16000\n        self.label_mapping = {\"real\": 0, \"fake\": 1, \"REAL\":0, \"FAKE\":1}\n        self.unfreeze_layers = [-1]  # Last transformer layer\n        self.base_lr = 1e-5\n        self.classifier_lr_multiplier = 10\n        self.lr_decay = 0.95\n        self.min_lr = 1e-7\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:55:27.069564Z","iopub.execute_input":"2025-04-07T00:55:27.070199Z","iopub.status.idle":"2025-04-07T00:55:27.155631Z","shell.execute_reply.started":"2025-04-07T00:55:27.070168Z","shell.execute_reply":"2025-04-07T00:55:27.154649Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\nimport torchaudio\n\nclass AudioAugmenter:\n    def __init__(self, sample_rate=16000):\n        self.augment = Compose([\n            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n            TimeStretch(min_rate=0.95, max_rate=1.05, p=0.2),  # More conservative stretching\n            PitchShift(min_semitones=-1, max_semitones=1, p=0.2),  # Reduced semitone range\n            Shift(min_shift=-0.1, max_shift=0.1, p=0.2),\n        ])\n        self.sample_rate = sample_rate\n        \n    def __call__(self, waveform):\n        \"\"\"Process and augment waveform while maintaining proper dimensions\"\"\"\n        # Convert to numpy and ensure proper shape\n        np_waveform = waveform.numpy()\n        \n        # Handle different channel configurations\n        if np_waveform.ndim == 2:  # [channels, time]\n            # Convert multi-channel to mono by averaging\n            np_waveform = np.mean(np_waveform, axis=0)\n        elif np_waveform.ndim == 1:  # [time]\n            pass  # Already mono\n        else:\n            raise ValueError(f\"Unexpected waveform shape: {np_waveform.shape}\")\n        \n        # Apply augmentations\n        augmented = self.augment(\n            samples=np_waveform,\n            sample_rate=self.sample_rate\n        )\n        \n        # Convert back to tensor with proper dimensions [1, time]\n        return torch.from_numpy(augmented).unsqueeze(0).float()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:28.564383Z","iopub.execute_input":"2025-04-07T00:57:28.564737Z","iopub.status.idle":"2025-04-07T00:57:28.740117Z","shell.execute_reply.started":"2025-04-07T00:57:28.564710Z","shell.execute_reply":"2025-04-07T00:57:28.739274Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"markdown","source":"> **Audiomentations library used to impart noise and other impairments to our audio samples. To train on the original audio samples comment out the parts in the below code where its commented \"#Impairments\".**","metadata":{}},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, root_dir, config, augment=False):\n        self.config = config\n        self.file_list = []\n        self.labels = []\n        self.augment = augment #Impairments\n        self._load_data(root_dir)\n        self.augmenter = AudioAugmenter(sample_rate=config.sample_rate) if augment else None\n        \n    def _load_data(self, root_dir):\n        \"\"\"Improved data loading with better error handling\"\"\"\n        for label_name, label in config.label_mapping.items():\n            folder = os.path.join(root_dir, label_name)\n            if not os.path.exists(folder):\n                print(f\"Warning: Missing directory: {folder}\")\n                continue\n                \n            files = glob.glob(os.path.join(folder, \"*.*\"))\n            print(f\"Found {len(files)} files in {folder}\")\n            \n            for file in files:\n                if self._is_valid_audio(file):\n                    self.file_list.append(file)\n                    self.labels.append(label)\n                else:\n                    print(f\"Warning: Skipping invalid file: {file}\")\n\n\n        # Shuffle with seed for reproducibility\n        random.seed(42)\n        combined = list(zip(self.file_list, self.labels))\n        random.shuffle(combined)\n        self.file_list, self.labels = zip(*combined) if combined else ([], [])\n\n    def _is_valid_audio(self, file_path):\n        \"\"\"Enhanced validation with detailed logging\"\"\"\n        try:\n            # Check file size\n            if os.path.getsize(file_path) == 0:\n                print(f\"Empty file: {file_path}\")\n                return False\n                \n            # Try loading the file\n            waveform, sr = torchaudio.load(file_path)\n            if waveform.nelement() == 0:\n                return False\n            if waveform.shape[0] not in [1, 2]:  # Mono or stereo\n                return False\n            if waveform.shape[1] < 100:  # Minimum 100 samples\n                print(f\"Short audio: {file_path} ({waveform.shape[1]} samples)\")\n                return False\n            return True\n        except Exception as e:\n            print(f\"Error loading {file_path}: {str(e)}\")\n            return False\n\n    def __getitem__(self, idx):\n        try:\n            waveform, sr = torchaudio.load(self.file_list[idx])\n            \n            # Resample if necessary\n            if sr != config.sample_rate:\n                resampler = torchaudio.transforms.Resample(sr, config.sample_rate)\n                waveform = resampler(waveform)\n\n            if self.augment and self.augmenter: #Impairments\n                waveform = self.augmenter(waveform) #Impairments\n\n            # Convert to mono and process\n            waveform = self._process_waveform(waveform)\n            label = self.labels[idx]\n\n            return waveform.squeeze(0), label\n        except Exception as e:\n            print(f\"Error processing {self.file_list[idx]}: {str(e)}\")\n            return torch.zeros((1, config.max_length)), 0  # Return dummy data\n\n    def _process_waveform(self, waveform):\n        \"\"\"Guarantee 2D output [1, max_length] regardless of input\"\"\"\n        # Convert to 2D if needed\n        if waveform.dim() == 1:\n            waveform = waveform.unsqueeze(0)  # [1, time]\n        elif waveform.dim() > 2:\n            waveform = waveform.view(-1, waveform.size(-1))  # Flatten to 2D\n        \n        # Convert to mono\n        if waveform.size(0) > 1:\n            waveform = waveform.mean(dim=0, keepdim=True)\n\n        # Trim/pad to exact length\n        if waveform.size(1) > self.config.max_length:\n            waveform = waveform[:, :self.config.max_length]\n        else:\n            pad_amount = self.config.max_length - waveform.size(1)\n            waveform = torch.nn.functional.pad(waveform, (0, pad_amount))\n            \n        return waveform  # Guaranteed [1, max_length]\n\n    def __len__(self):\n        \"\"\"Returns the total number of samples in the dataset\"\"\"\n        return len(self.file_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.568097Z","iopub.execute_input":"2025-04-07T00:57:35.568768Z","iopub.status.idle":"2025-04-07T00:57:35.581065Z","shell.execute_reply.started":"2025-04-07T00:57:35.568737Z","shell.execute_reply":"2025-04-07T00:57:35.580304Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## HuBERT Classification","metadata":{}},{"cell_type":"code","source":"class HuBERTClassifier(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Load pre-trained HuBERT\n        self.hubert = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n        self._freeze_layers()\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, len(config.label_mapping))\n        )\n\n    def _freeze_layers(self):\n        \"\"\"Improved layer freezing with logging\"\"\"\n        total_layers = len(self.hubert.encoder.layers)\n        print(f\"Total HuBERT layers: {total_layers}\")\n        \n        for i, layer in enumerate(self.hubert.encoder.layers):\n            if i not in self.config.unfreeze_layers:\n                for param in layer.parameters():\n                    param.requires_grad = False\n            else:\n                print(f\"Unfreezing layer {i}\")\n\n    def forward(self, input_values):\n        \"\"\"Handle [batch, channels, time] input\"\"\"\n        # Convert to HuBERT-compatible 2D [batch, time]\n        if input_values.dim() == 3:\n            input_values = input_values.squeeze(1)  # Remove channel dim\n            \n        outputs = self.hubert(input_values)\n        pooled_output = outputs.last_hidden_state.mean(dim=1)\n        return self.classifier(pooled_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.582123Z","iopub.execute_input":"2025-04-07T00:57:35.582319Z","iopub.status.idle":"2025-04-07T00:57:35.603246Z","shell.execute_reply.started":"2025-04-07T00:57:35.582302Z","shell.execute_reply":"2025-04-07T00:57:35.602669Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"Robust collate function handling various audio dimensions\"\"\"\n    # 1. Filter invalid entries\n    batch = [b for b in batch if b is not None]\n    \n    if not batch:\n        return torch.zeros((0, 1, config.max_length)), torch.zeros(0, dtype=torch.long)\n    \n    # 2. Separate components\n    waveforms, labels = zip(*batch)\n    \n    waveforms = torch.stack(waveforms)  # [batch, 1, max_length]\n    labels = torch.tensor(labels, dtype=torch.long)\n    \n    return waveforms, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.604640Z","iopub.execute_input":"2025-04-07T00:57:35.604833Z","iopub.status.idle":"2025-04-07T00:57:35.622647Z","shell.execute_reply.started":"2025-04-07T00:57:35.604816Z","shell.execute_reply":"2025-04-07T00:57:35.621875Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Metrics Saving","metadata":{}},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nclass DiskMetricsCollector:\n    def __init__(self, base_dir=\"/kaggle/working/metrics\"):\n        self.base_dir = Path(base_dir)\n        self.base_dir.mkdir(parents=True, exist_ok=True)\n        self.metrics_file = self.base_dir / \"all_metrics.json\"\n        \n        # Initialize empty metrics structure if file doesn't exist\n        if not self.metrics_file.exists():\n            with open(self.metrics_file, \"w\") as f:\n                json.dump({}, f)\n    \n    def add_metrics(self, round_num, client_id, metrics):\n        \"\"\"Append metrics to consolidated JSON file\"\"\"\n        # Load existing data\n        with open(self.metrics_file, \"r\") as f:\n            all_metrics = json.load(f)\n        \n        # Create round entry if not exists\n        round_key = f\"round_{round_num}\"\n        if round_key not in all_metrics:\n            all_metrics[round_key] = {}\n        \n        # Add client metrics\n        client_key = f\"client_{client_id}\"\n        all_metrics[round_key][client_key] = {\n            \"loss\": metrics[\"loss\"],\n            \"accuracy\": metrics[\"accuracy\"]\n        }\n        \n        # Save back to file\n        with open(self.metrics_file, \"w\") as f:\n            json.dump(all_metrics, f, indent=2)\n\n    def plot_round(self, round_num):\n        \"\"\"Plot metrics directly from JSON\"\"\"\n        with open(self.metrics_file, \"r\") as f:\n            all_metrics = json.load(f)\n        \n        round_key = f\"round_{round_num}\"\n        if round_key not in all_metrics:\n            print(f\"No metrics for round {round_num}\")\n            return\n        \n        plt.figure(figsize=(12, 6))\n        \n        for client_key, metrics in all_metrics[round_key].items():\n            client_id = client_key.split(\"_\")[1]\n            epochs = range(1, len(metrics[\"loss\"]) + 1)\n            \n            plt.subplot(1, 2, 1)\n            plt.plot(epochs, metrics[\"loss\"], label=f'Client {client_id}')\n            plt.title(f'Round {round_num} - Loss')\n            plt.xlabel('Epoch')\n            \n            plt.subplot(1, 2, 2)\n            plt.plot(epochs, metrics[\"accuracy\"], label=f'Client {client_id}')\n            plt.title(f'Round {round_num} - Accuracy')\n            plt.xlabel('Epoch')\n        \n        plt.legend()\n        plt.tight_layout()\n        plt.show()\n        plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.623340Z","iopub.execute_input":"2025-04-07T00:57:35.623547Z","iopub.status.idle":"2025-04-07T00:57:35.639801Z","shell.execute_reply.started":"2025-04-07T00:57:35.623529Z","shell.execute_reply":"2025-04-07T00:57:35.639211Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Federated Setup","metadata":{}},{"cell_type":"code","source":"import gc\nclass FlowerClient(fl.client.NumPyClient):\n    def __init__(self, model, train_data, test_data, config, client_id,metrics_collector):\n        self.client_id = client_id\n        self.model = model.to(config.device)\n        self.config = config\n        self.server_round = 0\n        self.train_loader = DataLoader(\n            train_data,\n            batch_size=config.batch_size,\n            shuffle=True,\n            collate_fn=collate_fn,\n            drop_last=True\n        )\n        self.test_loader = DataLoader(\n            test_data,\n            batch_size=config.batch_size,\n            collate_fn=collate_fn\n        )\n        self.optimizer = self._create_optimizer()\n        self.criterion = nn.CrossEntropyLoss()\n        self.metrics_collector = metrics_collector\n\n    \n    # def get_parameters(self, config):\n    #     \"\"\"Proper parameter serialization using state_dict\"\"\"\n    #     return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    \n    # def set_parameters(self, parameters):\n    #     \"\"\"Proper parameter deserialization using state_dict\"\"\"\n    #     params_dict = zip(self.model.state_dict().keys(), parameters)\n    #     state_dict = {k: torch.tensor(v) for k, v in params_dict}\n    #     self.model.load_state_dict(state_dict, strict=True)\n    \n    \n    def _create_optimizer(self):\n        \"\"\"Optimizer with learning rate decay and stability features\"\"\"\n        decay_factor = max(\n            self.config.lr_decay ** self.server_round,\n            self.config.min_lr / self.config.base_lr\n        )\n        \n        params = [\n            {\n                \"params\": self.model.hubert.parameters(),\n                \"lr\": self.config.base_lr * decay_factor,\n                \"weight_decay\": 1e-5\n            },\n            {\n                \"params\": self.model.classifier.parameters(),\n                \"lr\": (self.config.base_lr * self.config.classifier_lr_multiplier) * decay_factor,\n                \"weight_decay\": 1e-4\n            }\n        ]\n        \n        return optim.Adam(\n            params,\n            eps=1e-7,\n            amsgrad=True  # Improved convergence stability\n        )\n    \n    def get_parameters(self, config):\n        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    \n    def set_parameters(self, parameters):\n        if any(np.isnan(p).any() for p in parameters):\n            raise ValueError(f\"Client {self.client_id} received NaN parameters\")\n            \n        params_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = {\n            k: torch.tensor(v).to(self.config.device)\n            for k, v in params_dict\n        }\n        self.model.load_state_dict(state_dict, strict=True)\n\n        # if not parameters:\n        #     raise ValueError(\"Received empty parameters\")\n        \n        # try:\n        #     # Convert numpy arrays to tensors\n        #     params_dict = zip(self.model.state_dict().keys(), parameters)\n        #     state_dict = {\n        #         k: torch.tensor(v).to(self.config.device)\n        #         for k, v in params_dict\n        #     }\n            \n        #     # Strict loading with informative errors\n        #     self.model.load_state_dict(state_dict, strict=True)\n            \n        # except RuntimeError as e:\n        #     # Wrap PyTorch errors for Flower compatibility\n        #     raise fl.common.parameter.ParametersError(str(e)) from e\n\n    \n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        self.server_round = config.get(\"server_round\", 1)\n        self.optimizer = self._create_optimizer()  # Update optimizer for current round\n        self.set_parameters(parameters)\n        self.model.train()\n    \n        # Track per-epoch metrics\n        epoch_losses = []\n        epoch_accuracies = []\n        epoch_metrics = {'loss': [], 'accuracy': []}\n    \n        try:\n            if len(self.train_loader.dataset) == 0:\n                print(f\"Client has no training data!\")\n                return (\n                    self.get_parameters({}),\n                    0,\n                    {\"loss\": 0.0, \"accuracy\": 0.0}\n                )\n    \n            for epoch in range(self.config.epochs_per_round):\n                epoch_loss = 0.0\n                correct = 0\n                total = 0\n                progress_bar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}\")\n    \n                for batch_idx, (data, targets) in enumerate(progress_bar):\n                    data, targets = data.to(self.config.device), targets.to(self.config.device)\n                    \n                    self.optimizer.zero_grad()\n                    outputs = self.model(data)\n\n                    if torch.isnan(outputs).any():\n                        print(f\"NaN outputs detected, skipping batch\")\n                        continue\n                    loss = self.criterion(outputs, targets)\n\n                    if torch.isnan(loss):\n                        print(f\"NaN loss detected, resetting parameters\")\n                        self.set_parameters(parameters)  # Reset to server parameters\n                        return self.get_parameters({}), 0, {}\n                        \n                    loss.backward()\n\n                    torch.nn.utils.clip_grad_norm_(\n                        self.model.parameters(),\n                        max_norm=1.0,\n                        norm_type=2.0\n                    )\n                    \n                    self.optimizer.step()\n    \n                    epoch_loss += loss.item()\n                    preds = outputs.argmax(dim=1)\n                    correct += (preds == targets).sum().item()\n                    total += targets.size(0)\n    \n                    progress_bar.set_postfix(loss=loss.item())\n                    \n                    del outputs, loss\n                    torch.cuda.empty_cache()\n                    gc.collect()\n    \n                # Calculate metrics properly\n                if len(self.train_loader) > 0 and total > 0:\n                    avg_loss = epoch_loss / len(self.train_loader)\n                    accuracy = correct / total\n                else:  # Handle empty/corrupted data cases\n                    avg_loss = 0.0\n                    accuracy = 0.0\n    \n                epoch_losses.append(avg_loss)\n                epoch_accuracies.append(accuracy)\n                epoch_metrics['loss'].append(avg_loss)\n                epoch_metrics['accuracy'].append(accuracy)  # Fixed variable name\n    \n        except Exception as e:\n            print(f\"Training error: {str(e)}\")\n            return self.get_parameters({}), 0, {}\n    \n        # Store metrics\n        self.metrics_collector.add_metrics(\n            self.server_round,  # Use the server_round from config\n            self.client_id,\n            {'loss': epoch_losses, 'accuracy': epoch_accuracies}\n        )\n    \n        # Calculate averages\n        avg_loss = sum(epoch_losses)/len(epoch_losses) if epoch_losses else 0.0\n        avg_accuracy = sum(epoch_accuracies)/len(epoch_accuracies) if epoch_accuracies else 0.0\n    \n        return (\n            self.get_parameters({}), \n            len(self.train_loader.dataset),\n            {\"loss\": float(avg_loss), \"accuracy\": float(avg_accuracy)}\n        )\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        self.model.eval()\n        \n        total_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for data, targets in self.test_loader:\n                data, targets = data.to(self.config.device), targets.to(self.config.device)\n                outputs = self.model(data)\n                total_loss += self.criterion(outputs, targets).item()\n                preds = outputs.argmax(dim=1)\n                correct += (preds == targets).sum().item()\n\n        accuracy = correct / len(self.test_loader.dataset)\n        avg_loss = total_loss / len(self.test_loader)\n        return (\n            float(avg_loss), \n            len(self.test_loader.dataset), \n            {\n                \"loss\":float(avg_loss),\n                \"accuracy\": float(accuracy)\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.725153Z","iopub.execute_input":"2025-04-07T00:57:35.725375Z","iopub.status.idle":"2025-04-07T00:57:35.743306Z","shell.execute_reply.started":"2025-04-07T00:57:35.725357Z","shell.execute_reply":"2025-04-07T00:57:35.742493Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CustomFedAvg(fl.server.strategy.FedAvg):\n    def __init__(self, metrics_collector, initial_parameters=None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.metrics_collector = metrics_collector\n        self.current_parameters = initial_parameters  # Initialize with provided parameters\n        self.initial_parameters = initial_parameters  # Store initial parameters\n\n    def aggregate_fit(self, server_round, results, failures):\n        # Call parent aggregation first\n        aggregated = super().aggregate_fit(server_round, results, failures)\n        \n        if aggregated is not None:\n            # Store the aggregated parameters\n            self.current_parameters = aggregated[0]\n        elif self.current_parameters is None:\n            # Fallback to initial parameters if no aggregation happened\n            self.current_parameters = self.initial_parameters\n            \n        return aggregated\n\n    def get_parameters(self, config):\n        # Return current parameters or initial ones if none exist\n        if self.current_parameters is not None:\n            return self.current_parameters\n        return self.initial_parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.744494Z","iopub.execute_input":"2025-04-07T00:57:35.744772Z","iopub.status.idle":"2025-04-07T00:57:35.765001Z","shell.execute_reply.started":"2025-04-07T00:57:35.744745Z","shell.execute_reply":"2025-04-07T00:57:35.764253Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Visualisations","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Add visualization functions before main()\ndef plot_training_metrics(history):\n    \"\"\"Plot training metrics from Flower history\"\"\"\n    if not history.metrics_distributed:\n        print(\"No metrics available in history\")\n        return\n    \n    plt.figure(figsize=(12, 5))\n    \n    # Training Loss\n    plt.subplot(1, 2, 1)\n    if \"train_loss\" in history.metrics_distributed:\n        losses = [metric[1] for metric in history.metrics_distributed[\"train_loss\"]]\n        plt.plot(losses, marker='o', label='Training Loss')\n    if \"test_loss\" in history.metrics_distributed:\n        losses = [metric[1] for metric in history.metrics_distributed[\"test_loss\"]]\n        plt.plot(losses, marker='o', label='Test Loss')\n    plt.title('Loss per Round')\n    plt.xlabel('Round')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Accuracy\n    plt.subplot(1, 2, 2)\n    if \"train_accuracy\" in history.metrics_distributed:\n        accs = [metric[1] for metric in history.metrics_distributed[\"train_accuracy\"]]\n        plt.plot(accs, marker='o', label='Training Accuracy')\n    if \"test_accuracy\" in history.metrics_distributed:\n        accs = [metric[1] for metric in history.metrics_distributed[\"test_accuracy\"]]\n        plt.plot(accs, marker='o', label='Test Accuracy')\n    plt.title('Accuracy per Round')\n    plt.xlabel('Round')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.766757Z","iopub.execute_input":"2025-04-07T00:57:35.766957Z","iopub.status.idle":"2025-04-07T00:57:35.783325Z","shell.execute_reply.started":"2025-04-07T00:57:35.766940Z","shell.execute_reply":"2025-04-07T00:57:35.782578Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def central_evaluation(model, test_loader, device):\n    \"\"\"Robust central evaluation with error handling\"\"\"\n    model.eval()\n    all_labels = []\n    all_preds = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            try:\n                # Handle different batch formats\n                if isinstance(batch, (list, tuple)):\n                    data, targets = batch[0], batch[1]\n                else:  # Handle single-tensor batches\n                    data, targets = batch, None\n\n                if data is None:\n                    continue\n\n                # Move to device\n                inputs = data.to(device)\n                targets = targets.to(device) if targets is not None else None\n                \n                # Forward pass\n                outputs = model(inputs)\n                probs = torch.softmax(outputs, dim=1)\n                preds = torch.argmax(outputs, dim=1)\n                \n                # Only store if targets exist\n                if targets is not None:\n                    all_labels.extend(targets.cpu().numpy())\n                    all_preds.extend(preds.cpu().numpy())\n                    all_probs.extend(probs.cpu().numpy())\n                    \n            except Exception as e:\n                print(f\"Error processing batch: {str(e)}\")\n                continue\n    \n    return all_labels, all_preds, np.array(all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.784541Z","iopub.execute_input":"2025-04-07T00:57:35.784727Z","iopub.status.idle":"2025-04-07T00:57:35.803940Z","shell.execute_reply.started":"2025-04-07T00:57:35.784711Z","shell.execute_reply":"2025-04-07T00:57:35.803163Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, normalize=False, figsize=(8, 6)):\n    \"\"\"\n    Plot a confusion matrix with enhanced visualization\n    \n    Parameters:\n    y_true (array): True labels\n    y_pred (array): Predicted labels\n    class_names (list): List of class names\n    normalize (bool): Whether to normalize the matrix\n    figsize (tuple): Figure size\n    \"\"\"\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Normalize if requested\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        fmt = '.2%'\n        title = 'Normalized Confusion Matrix'\n    else:\n        fmt = 'd'\n        title = 'Confusion Matrix'\n    \n    # Create figure\n    plt.figure(figsize=figsize)\n    \n    # Create heatmap\n    heatmap = sns.heatmap(\n        cm,\n        annot=True,\n        fmt=fmt,\n        cmap='Blues',\n        xticklabels=class_names,\n        yticklabels=class_names,\n        cbar=False,\n        linewidths=0.5,\n        annot_kws={'size': 12}\n    )\n    \n    # Add labels and title\n    plt.title(title, fontsize=14, pad=20)\n    plt.xlabel('Predicted Label', fontsize=12)\n    plt.ylabel('True Label', fontsize=12)\n    \n    # Adjust tick labels\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    plt.yticks(rotation=0, fontsize=10)\n    \n    # Add colorbar\n    plt.colorbar(heatmap.collections[0]).ax.set_ylabel('Counts' if not normalize else 'Percentage', \n                                                    rotation=270, labelpad=15)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return cm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.804736Z","iopub.execute_input":"2025-04-07T00:57:35.804966Z","iopub.status.idle":"2025-04-07T00:57:35.825274Z","shell.execute_reply.started":"2025-04-07T00:57:35.804937Z","shell.execute_reply":"2025-04-07T00:57:35.824693Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc, RocCurveDisplay\n\n\ndef plot_roc_curve(y_true, y_probs, class_names):\n    # Handle binary vs multi-class cases\n    n_classes = len(class_names)\n    \n    if n_classes == 2:\n        # Binary classification - use positive class probabilities\n        fpr, tpr, _ = roc_curve(y_true, y_probs[:, 1])  # Use second column\n        roc_auc = auc(fpr, tpr)\n        \n        plt.figure()\n        plt.plot(fpr, tpr, color='darkorange', lw=2,\n                 label=f'ROC curve (AUC = {roc_auc:.2f})')\n    else:\n        # Multi-class: One-vs-Rest\n        y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n        \n        plt.figure()\n        for i in range(n_classes):\n            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n            roc_auc = auc(fpr, tpr)\n            plt.plot(fpr, tpr, lw=2,\n                     label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"lower right\")\n    plt.title('ROC Curve' + (' (Binary)' if n_classes == 2 else ' (OvR)'))\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.826144Z","iopub.execute_input":"2025-04-07T00:57:35.826451Z","iopub.status.idle":"2025-04-07T00:57:35.845586Z","shell.execute_reply.started":"2025-04-07T00:57:35.826403Z","shell.execute_reply":"2025-04-07T00:57:35.844992Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# import torchaudio\n\n# def plot_comparison(raw, aug, sample_rate=16000):\n#     plt.figure(figsize=(18, 12))\n    \n#     # Time-align waveforms\n#     min_length = min(len(raw), len(aug))\n#     raw = raw[:min_length]\n#     aug = aug[:min_length]\n    \n#     # Create window function\n#     window = torch.hann_window(1024)\n    \n#     # Waveform plots with difference overlay\n#     plt.subplot(3, 1, 1)\n#     plt.plot(raw.numpy().squeeze(), 'b', alpha=0.6, label='Original')\n#     plt.plot(aug.numpy().squeeze(), 'r', alpha=0.4, label='Augmented')\n#     plt.plot(np.abs(raw.numpy().squeeze() - aug.numpy().squeeze()),'k', label='Difference')\n#     plt.xlabel(\"Time (s) (Samples)\")\n#     plt.ylabel(\"Amplitude\")\n#     plt.title(\"Waveform Comparison\")\n#     plt.legend()\n    \n#     # Spectral difference using correct parameters\n#     def create_spectrogram(waveform):\n#         return torchaudio.functional.spectrogram(\n#             waveform=waveform.unsqueeze(0),\n#             pad=0,\n#             window=window,\n#             n_fft=1024,\n#             hop_length=256,\n#             win_length=1024,\n#             power=2.0,\n#             normalized=False\n#         ).squeeze().log2().numpy()\n    \n#     S_raw = create_spectrogram(raw)\n#     S_aug = create_spectrogram(aug)\n    \n#     plt.subplot(3, 2, 3)\n#     plt.imshow(S_raw, aspect='auto', cmap='viridis', origin='lower')\n#     plt.xlabel(\"Time (s)\")\n#     plt.ylabel(\"Frequency (Hz)\")\n#     plt.title(\"Original Spectrogram\")\n#     plt.colorbar()\n    \n#     plt.subplot(3, 2, 4)\n#     plt.imshow(S_aug, aspect='auto', cmap='viridis', origin='lower')\n#     plt.xlabel(\"Time (s)\")\n#     plt.ylabel(\"Frequency (Hz)\")\n#     plt.title(\"Augmented Spectrogram\")\n#     plt.colorbar()\n    \n#     plt.subplot(3, 2, 5)\n#     plt.imshow(S_aug - S_raw, aspect='auto', cmap='coolwarm', origin='lower', vmin=-1, vmax=1)\n#     plt.xlabel(\"Time (s)\")\n#     plt.ylabel(\"Frequency (Hz)\")\n#     plt.title(\"Spectral Difference\")\n#     plt.colorbar()\n    \n#     plt.subplot(3, 2, 6)\n#     plt.specgram(raw.numpy().squeeze(), Fs=sample_rate, cmap='plasma', NFFT=1024, noverlap=512)\n#     plt.xlabel(\"Time (s)\")\n#     plt.ylabel(\"Frequency (Hz)\")\n#     plt.title(\"Original Spectrogram\")\n    \n#     plt.tight_layout()\n#     plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.846270Z","iopub.execute_input":"2025-04-07T00:57:35.846499Z","iopub.status.idle":"2025-04-07T00:57:35.865561Z","shell.execute_reply.started":"2025-04-07T00:57:35.846480Z","shell.execute_reply":"2025-04-07T00:57:35.864958Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_sample_waveform(dataset, index=0):\n#     \"\"\"Helper to get raw and augmented versions of same sample\"\"\"\n#     # Create non-augmented version\n#     raw_dataset = AudioDataset(\n#         root_dir=dataset.config.dirs[\"train\"],\n#         config=dataset.config,\n#         augment=False\n#     )\n    \n#     # Get raw waveform\n#     raw_waveform, label = raw_dataset[index]\n    \n#     # Get augmented waveform (create new dataset with augment=True)\n#     aug_dataset = AudioDataset(\n#         root_dir=dataset.config.dirs[\"train\"],\n#         config=dataset.config,\n#         augment=True\n#     )\n#     aug_waveform, _ = aug_dataset[index]\n    \n#     return raw_waveform, aug_waveform\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.866205Z","iopub.execute_input":"2025-04-07T00:57:35.866395Z","iopub.status.idle":"2025-04-07T00:57:35.885172Z","shell.execute_reply.started":"2025-04-07T00:57:35.866378Z","shell.execute_reply":"2025-04-07T00:57:35.884475Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# from IPython.display import Audio, display\n\n# def play_comparison(raw, aug, sr=16000):\n#     print(\"Original:\")\n#     display(Audio(raw.numpy().squeeze(), rate=sr))\n#     print(\"Augmented:\")\n#     display(Audio(aug.numpy().squeeze(), rate=sr))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.887448Z","iopub.execute_input":"2025-04-07T00:57:35.887638Z","iopub.status.idle":"2025-04-07T00:57:35.903904Z","shell.execute_reply.started":"2025-04-07T00:57:35.887622Z","shell.execute_reply":"2025-04-07T00:57:35.903232Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"ray.shutdown()\nray.init()\nos.environ[\"RAY_memory_monitor_refresh_ms\"]=\"0\"\n# os.environ[\"RAY_memory_usage_threshold\"] = \"0.98\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:35.905021Z","iopub.execute_input":"2025-04-07T00:57:35.905339Z","iopub.status.idle":"2025-04-07T00:57:40.063851Z","shell.execute_reply.started":"2025-04-07T00:57:35.905315Z","shell.execute_reply":"2025-04-07T00:57:40.062690Z"}},"outputs":[{"name":"stderr","text":"2025-04-07 00:57:38,622\tINFO worker.py:1771 -- Started a local Ray instance.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def weighted_avg(metrics, metric_name):\n    \"\"\"Helper function for metric aggregation\"\"\"\n    values = []\n    weights = []\n    for num_examples, m in metrics:\n        if metric_name in m:\n            values.append(m[metric_name])\n            weights.append(num_examples)\n    return sum(v * w for v, w in zip(values, weights)) / sum(weights) if weights else 0.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:40.064963Z","iopub.execute_input":"2025-04-07T00:57:40.065336Z","iopub.status.idle":"2025-04-07T00:57:40.071671Z","shell.execute_reply.started":"2025-04-07T00:57:40.065294Z","shell.execute_reply":"2025-04-07T00:57:40.070847Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Main function","metadata":{}},{"cell_type":"code","source":"from flwr.server.client_manager import SimpleClientManager  # Import missing class\nfrom torch.utils.data import random_split\n\ndef main():\n    try:\n        print(\"Starting federated learning setup\")\n        \n        # Load datasets\n        train_dataset = AudioDataset(config.dirs[\"train\"], config, augment = True)\n        train_size = int(1* len(train_dataset))\n        train_subset, _ = random_split(\n            train_dataset,\n            [train_size, len(train_dataset) - train_size],\n            generator=torch.Generator().manual_seed(42)\n        )\n\n        # if len(train_dataset) > 0:\n        #     # Get first sample's raw and augmented versions\n        #     raw_wave, aug_wave = get_sample_waveform(train_dataset, 2004)\n        #     # Plot comparison\n        #     plot_comparison(raw_wave, aug_wave)\n        #     play_comparison(raw_wave, aug_wave, config.sample_rate)\n        # else:\n        #     print(\"Dataset is empty - check your data paths!\")\n            \n        test_dataset = AudioDataset(config.dirs[\"test\"], config)\n        test_loader = DataLoader(test_dataset,\n                                 batch_size=config.batch_size,\n                                 collate_fn=collate_fn,\n                                 shuffle=False)\n\n        # Create metrics collector\n        metrics_collector = DiskMetricsCollector()\n        \n        # Split into client partitions\n        indices = list(range(len(train_subset)))\n        chunk_size = len(indices) // config.num_clients\n        \n        # Create client datasets\n        client_datasets = [\n            Subset(train_subset, indices[i*chunk_size:(i+1)*chunk_size])\n            for i in range(config.num_clients)\n        ]\n\n        print(f\"Using {len(train_subset)}/{len(train_dataset)} training samples\")\n        print(f\"Test samples: {len(test_dataset)}\")\n\n        # Define client creation function\n        def client_fn(cid: str) -> FlowerClient:\n            \"\"\"Create client with fresh model instance\"\"\"\n            client_id = int(cid)\n            torch.cuda.empty_cache()\n            model = HuBERTClassifier(config).to(config.device)  # Ensure model is on correct device\n            numpy_client = FlowerClient(\n                model=model,\n                train_data=client_datasets[client_id],\n                test_data=test_dataset,\n                config=config,\n                client_id=client_id,\n                metrics_collector=metrics_collector\n            )\n            return numpy_client.to_client()\n\n        # Initialize global model\n        initial_model = HuBERTClassifier(config).to(config.device)\n        initial_params = fl.common.ndarrays_to_parameters([\n            val.cpu().numpy() for _, val in initial_model.state_dict().items()\n        ])\n\n        # Configure strategy with proper aggregation\n        strategy = CustomFedAvg(\n            metrics_collector=metrics_collector,\n            min_fit_clients=config.num_clients,\n            min_available_clients=config.num_clients,\n            initial_parameters=initial_params,\n            fit_metrics_aggregation_fn=lambda metrics: {\n                \"train_loss\": weighted_avg(metrics, \"loss\"),\n                \"train_accuracy\": weighted_avg(metrics, \"accuracy\")\n            },\n            evaluate_metrics_aggregation_fn=lambda metrics: {\n                \"test_loss\": weighted_avg(metrics, \"loss\"),\n                \"test_accuracy\": weighted_avg(metrics, \"accuracy\")\n            },\n\n        )\n\n        print(\"Starting federated training\")\n        history = fl.simulation.start_simulation(\n            client_fn=client_fn,\n            num_clients=config.num_clients,\n            config=fl.server.ServerConfig(num_rounds=config.num_rounds),\n            strategy=strategy,\n            client_resources={\n                \"num_cpus\": 0.8,\n                \"num_gpus\": 0.25 if torch.cuda.is_available() else 0\n            },\n        )\n\n        print(\"\\nGenerating visualizations...\")\n        for round_num in range(1, config.num_rounds+1):\n            metrics_collector.plot_round(round_num)\n            print(\"\\nPlotting training metrics...\")\n            plot_training_metrics(history)\n\n        print(\"\\nPerforming central evaluation...\")\n        final_model = HuBERTClassifier(config).to(config.device)\n        params_obj = strategy.get_parameters(None)\n        \n        if params_obj is None:\n            print(\"Using initial parameters for evaluation\")\n            params_obj = initial_params\n            raise ValueError(\"No parameters found in strategy\")\n        final_params = fl.common.parameters_to_ndarrays(params_obj)\n\n        # Load parameters into the model\n        sd = final_model.state_dict()\n        param_names = [name for name, _ in final_model.named_parameters()]\n        assert len(final_params) == len(param_names), \\\n            f\"Parameter count mismatch: Model has {len(param_names)}, strategy supplied {len(final_params)}\"\n        \n        for (name, _), array in zip(final_model.named_parameters(), final_params):\n            sd[name] = torch.from_numpy(array).to(config.device)\n\n        final_model.load_state_dict(sd, strict=True)\n        final_model = final_model.to(config.device)\n\n        # Device verification\n        print(\"\\n=== Device Verification ===\")\n        print(f\"Model device: {next(final_model.parameters()).device}\")\n        sample_batch = next(iter(test_loader))[0]\n        print(f\"Data device: {sample_batch.device}\")\n\n        try:\n            y_true, y_pred, y_probs = central_evaluation(final_model, test_loader, config.device)\n        except Exception as e:\n            print(f\"Evaluation failed: {str(e)}\")\n            print(\"Model architecture:\", final_model)\n            print(\"Sample input shape:\", sample_batch.shape)\n            raise\n        \n        # Move test data to correct device\n        for batch in test_loader:\n            inputs, labels = batch\n            inputs = inputs.to(config.device)\n            labels = labels.to(config.device)\n\n         # Handle binary probabilities\n        print(f\"\\nProbability matrix shape: {y_probs.shape}\")\n        if y_probs.shape[1] == 1:\n            y_probs = np.hstack([1 - y_probs, y_probs])\n\n        class_names = [\"Real\", \"Fake\"]  # Define your classes\n        plot_confusion_matrix(y_true, y_pred, class_names)\n        plot_roc_curve(y_true, y_probs, class_names)\n\n        \n        from sklearn.metrics import classification_report\n        import pandas as pd\n        \n        print(\"\\n=== Class-wise Performance Metrics ===\")\n        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n        report_df = pd.DataFrame(report).transpose()\n        print(\"===full report===\\n\")\n        print(report_df)\n        print(\"\\n===selected report===\\n\")\n        print(report_df[[\"precision\", \"recall\", \"f1-score\"]].round(2))\n\n        return history\n\n    except Exception as e:\n        print(f\"Critical failure: {str(e)}\")\n        raise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:40.072347Z","iopub.execute_input":"2025-04-07T00:57:40.072639Z","iopub.status.idle":"2025-04-07T00:57:40.096168Z","shell.execute_reply.started":"2025-04-07T00:57:40.072611Z","shell.execute_reply":"2025-04-07T00:57:40.095289Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    history = main()  # Return history from main()\n    # Additional analysis using history can happen here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T00:57:40.097072Z","iopub.execute_input":"2025-04-07T00:57:40.097368Z","execution_failed":"2025-04-07T01:24:01.958Z"}},"outputs":[{"name":"stdout","text":"Starting federated learning setup\nFound 27000 files in /kaggle/input/imbalanceddataset/real90/real\nFound 3000 files in /kaggle/input/imbalanceddataset/real90/fake\nWarning: Missing directory: /kaggle/input/imbalanceddataset/real90/REAL\nWarning: Missing directory: /kaggle/input/imbalanceddataset/real90/FAKE\nFound 2500 files in /kaggle/input/fakes-and-reals/audio_test/audio_test/real\nFound 2500 files in /kaggle/input/fakes-and-reals/audio_test/audio_test/fake\nEmpty file: /kaggle/input/fakes-and-reals/audio_test/audio_test/fake/file32972.mp3\nWarning: Skipping invalid file: /kaggle/input/fakes-and-reals/audio_test/audio_test/fake/file32972.mp3\nWarning: Missing directory: /kaggle/input/fakes-and-reals/audio_test/audio_test/REAL\nWarning: Missing directory: /kaggle/input/fakes-and-reals/audio_test/audio_test/FAKE\nUsing 30000/30000 training samples\nTest samples: 4999\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e52fdb8abe452b8a94c3d6ed8c3395"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb2dd119e544163baf44ab517a00f2d"}},"metadata":{}},{"name":"stdout","text":"Total HuBERT layers: 12\n","output_type":"stream"},{"name":"stderr","text":"\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n\n\t\t$ flwr new  # Create a new Flower app from a template\n\n\t\t$ flwr run  # Run the Flower app in Simulation Mode\n\n\tUsing `start_simulation()` is deprecated.\n\n            This is a deprecated feature. It will be removed\n            entirely in future versions of Flower.\n        \n\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=20, no round_timeout\n","output_type":"stream"},{"name":"stdout","text":"Starting federated training\n","output_type":"stream"},{"name":"stderr","text":"2025-04-07 01:06:52,535\tINFO worker.py:1771 -- Started a local Ray instance.\n\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'object_store_memory': 8590521139.0, 'memory': 17181042279.0, 'accelerator_type:T4': 1.0, 'GPU': 2.0}\n\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 0.8, 'num_gpus': 0.25}\n\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 5 actors\n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n\u001b[36m(pid=653)\u001b[0m 2025-04-07 01:06:57.794508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=653)\u001b[0m 2025-04-07 01:06:57.863349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=658)\u001b[0m 2025-04-07 01:06:57.956255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[36m(ClientAppActor pid=655)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=655)\u001b[0m \n\u001b[36m(ClientAppActor pid=655)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=655)\u001b[0m             entirely in future versions of Flower.\n\u001b[36m(ClientAppActor pid=655)\u001b[0m         \n\u001b[36m(pid=697)\u001b[0m 2025-04-07 01:06:58.662413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n\u001b[36m(pid=697)\u001b[0m 2025-04-07 01:06:58.746551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(pid=697)\u001b[0m 2025-04-07 01:06:58.771717: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=657)\u001b[0m \n\u001b[36m(ClientAppActor pid=657)\u001b[0m         \n\u001b[36m(ClientAppActor pid=697)\u001b[0m \n\u001b[36m(ClientAppActor pid=697)\u001b[0m         \n\u001b[36m(ClientAppActor pid=658)\u001b[0m \n\u001b[36m(ClientAppActor pid=658)\u001b[0m         \n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=655)\u001b[0m Total HuBERT layers: 12\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 0/937 [00:00<?, ?it/s]\nEpoch 1:   0%|          | 0/937 [00:02<?, ?it/s, loss=1.35]\n\u001b[36m(ClientAppActor pid=658)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=658)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=658)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   0%|          | 1/937 [00:03<50:31,  3.24s/it, loss=1.35]\nEpoch 1:   0%|          | 0/937 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   0%|          | 0/937 [00:02<?, ?it/s, loss=1.32]\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   1%|          | 7/937 [00:08<14:19,  1.08it/s, loss=1.25]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:   1%|▏         | 13/937 [00:13<12:41,  1.21it/s, loss=1.16]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   2%|▏         | 21/937 [00:19<10:52,  1.40it/s, loss=1.04]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:   3%|▎         | 26/937 [00:23<11:50,  1.28it/s, loss=1.11] \u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:   4%|▎         | 33/937 [00:28<11:54,  1.27it/s, loss=0.954]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:   5%|▍         | 43/937 [00:34<10:39,  1.40it/s, loss=0.736]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:   5%|▍         | 46/937 [00:39<11:40,  1.27it/s, loss=0.938]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:   6%|▌         | 53/937 [00:44<11:33,  1.28it/s, loss=0.583]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:   7%|▋         | 64/937 [00:49<10:37,  1.37it/s, loss=0.477]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   7%|▋         | 66/937 [00:54<11:20,  1.28it/s, loss=0.252]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:   8%|▊         | 73/937 [00:59<11:09,  1.29it/s, loss=0.5]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:   9%|▊         | 80/937 [01:04<10:36,  1.35it/s, loss=0.384]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  10%|▉         | 90/937 [01:10<10:51,  1.30it/s, loss=0.438]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  10%|█         | 96/937 [01:15<11:52,  1.18it/s, loss=0.865] \u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  11%|█         | 99/937 [01:19<11:23,  1.23it/s, loss=0.106]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  12%|█▏        | 112/937 [01:24<10:08,  1.36it/s, loss=0.865]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  13%|█▎        | 119/937 [01:29<09:32,  1.43it/s, loss=0.388]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  13%|█▎        | 119/937 [01:35<09:23,  1.45it/s, loss=0.937]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  13%|█▎        | 126/937 [01:40<10:07,  1.33it/s, loss=0.0793]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  14%|█▍        | 132/937 [01:45<11:17,  1.19it/s, loss=0.0402]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  15%|█▍        | 139/937 [01:50<09:17,  1.43it/s, loss=0.041]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  16%|█▌        | 146/937 [01:55<10:05,  1.31it/s, loss=0.471]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  17%|█▋        | 156/937 [02:01<09:36,  1.36it/s, loss=0.0958]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  17%|█▋        | 159/937 [02:05<10:22,  1.25it/s, loss=0.492]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  18%|█▊        | 166/937 [02:10<09:49,  1.31it/s, loss=0.407]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  19%|█▉        | 176/937 [02:16<09:45,  1.30it/s, loss=0.784]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  19%|█▉        | 179/937 [02:21<09:56,  1.27it/s, loss=0.463]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  20%|█▉        | 186/937 [02:26<09:26,  1.33it/s, loss=0.0394]\u001b[32m [repeated 58x across cluster]\u001b[0m\nEpoch 1:  20%|██        | 192/937 [02:31<09:41,  1.28it/s, loss=0.0424]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  21%|██        | 199/937 [02:36<08:57,  1.37it/s, loss=0.483]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  23%|██▎       | 217/937 [02:41<08:14,  1.46it/s, loss=0.0434]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  24%|██▍       | 224/937 [02:46<08:39,  1.37it/s, loss=0.267]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  24%|██▎       | 222/937 [02:52<10:06,  1.18it/s, loss=0.762]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  25%|██▌       | 237/937 [02:56<07:57,  1.47it/s, loss=0.0257]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  25%|██▌       | 235/937 [03:02<08:55,  1.31it/s, loss=0.192]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  26%|██▌       | 239/937 [03:07<08:47,  1.32it/s, loss=0.0214]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  26%|██▌       | 244/937 [03:12<08:24,  1.37it/s, loss=0.0388]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  27%|██▋       | 255/937 [03:18<08:32,  1.33it/s, loss=0.841]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  28%|██▊       | 258/937 [03:22<10:16,  1.10it/s, loss=0.0272]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  29%|██▊       | 268/937 [03:28<08:16,  1.35it/s, loss=0.417]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  31%|███       | 287/937 [03:32<07:28,  1.45it/s, loss=0.0379]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  30%|██▉       | 280/937 [03:38<08:20,  1.31it/s, loss=0.424] \u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  30%|██▉       | 280/937 [03:42<09:31,  1.15it/s, loss=0.52]  \u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  31%|███▏      | 294/937 [03:48<07:36,  1.41it/s, loss=0.806]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  31%|███▏      | 293/937 [03:53<08:23,  1.28it/s, loss=0.0473]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  32%|███▏      | 299/937 [03:58<08:23,  1.27it/s, loss=0.909]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  35%|███▌      | 329/937 [04:03<07:30,  1.35it/s, loss=0.292] \u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  33%|███▎      | 313/937 [04:08<07:52,  1.32it/s, loss=0.868] \u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  34%|███▍      | 320/937 [04:13<07:32,  1.36it/s, loss=0.681]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  37%|███▋      | 350/937 [04:18<07:49,  1.25it/s, loss=0.0477]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  36%|███▌      | 333/937 [04:24<07:58,  1.26it/s, loss=0.402]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  39%|███▉      | 364/937 [04:29<07:12,  1.32it/s, loss=0.028]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  37%|███▋      | 346/937 [04:34<07:38,  1.29it/s, loss=0.0856]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  38%|███▊      | 360/937 [04:39<07:02,  1.37it/s, loss=0.397]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  39%|███▉      | 366/937 [04:44<07:20,  1.30it/s, loss=0.325]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  40%|███▉      | 373/937 [04:50<07:53,  1.19it/s, loss=0.111]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  40%|████      | 379/937 [04:54<06:52,  1.35it/s, loss=0.361]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  41%|████      | 385/937 [04:59<07:43,  1.19it/s, loss=1.02]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  41%|████      | 385/937 [05:04<07:34,  1.21it/s, loss=0.0311]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  42%|████▏     | 392/937 [05:09<06:45,  1.35it/s, loss=0.0318]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  43%|████▎     | 399/937 [05:15<06:38,  1.35it/s, loss=0.0221]\u001b[32m [repeated 58x across cluster]\u001b[0m\nEpoch 1:  46%|████▌     | 433/937 [05:20<05:46,  1.46it/s, loss=0.489]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  45%|████▍     | 421/937 [05:25<06:25,  1.34it/s, loss=0.0332]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  45%|████▍     | 418/937 [05:30<07:13,  1.20it/s, loss=0.844]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  45%|████▌     | 424/937 [05:35<06:46,  1.26it/s, loss=0.017]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  47%|████▋     | 441/937 [05:41<06:37,  1.25it/s, loss=0.599] \u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  48%|████▊     | 446/937 [05:45<05:50,  1.40it/s, loss=0.0708]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  47%|████▋     | 444/937 [05:51<06:09,  1.34it/s, loss=0.0235]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  49%|████▉     | 462/937 [05:56<05:30,  1.44it/s, loss=0.0842]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  50%|████▉     | 467/937 [06:01<05:41,  1.38it/s, loss=0.896]\u001b[32m [repeated 58x across cluster]\u001b[0m\nEpoch 1:  50%|█████     | 473/937 [06:06<06:08,  1.26it/s, loss=0.71]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  51%|█████▏    | 482/937 [06:11<06:13,  1.22it/s, loss=0.043]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  51%|█████     | 478/937 [06:16<05:56,  1.29it/s, loss=0.464]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  52%|█████▏    | 485/937 [06:21<05:50,  1.29it/s, loss=0.353]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  53%|█████▎    | 500/937 [06:27<05:44,  1.27it/s, loss=0.0239]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  53%|█████▎    | 497/937 [06:31<06:03,  1.21it/s, loss=0.445]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  55%|█████▍    | 511/937 [06:36<05:50,  1.21it/s, loss=0.109]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  54%|█████▍    | 510/937 [06:41<05:32,  1.28it/s, loss=0.665]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  55%|█████▌    | 517/937 [06:46<05:12,  1.34it/s, loss=0.102]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  56%|█████▋    | 529/937 [06:52<06:00,  1.13it/s, loss=1.07]  \u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  57%|█████▋    | 536/937 [06:57<04:56,  1.35it/s, loss=0.0188]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  57%|█████▋    | 536/937 [07:02<05:16,  1.27it/s, loss=0.0497]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  59%|█████▉    | 552/937 [07:07<05:02,  1.27it/s, loss=0.579]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  59%|█████▉    | 555/937 [07:12<04:51,  1.31it/s, loss=0.628]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  60%|██████    | 566/937 [07:17<04:16,  1.45it/s, loss=1.83]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  61%|██████    | 568/937 [07:22<04:37,  1.33it/s, loss=0.85]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  61%|██████    | 569/937 [07:27<05:05,  1.21it/s, loss=0.0646]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  62%|██████▏   | 581/937 [07:32<04:34,  1.30it/s, loss=0.0154]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  63%|██████▎   | 591/937 [07:38<04:24,  1.31it/s, loss=0.0146]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  64%|██████▎   | 597/937 [07:43<04:37,  1.22it/s, loss=0.492] \u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  64%|██████▍   | 601/937 [07:48<04:16,  1.31it/s, loss=0.532]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  64%|██████▍   | 602/937 [07:52<04:03,  1.38it/s, loss=0.246]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  66%|██████▌   | 617/937 [07:58<03:54,  1.36it/s, loss=0.0485]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  70%|██████▉   | 654/937 [08:02<03:35,  1.31it/s, loss=0.027]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  71%|███████   | 662/937 [08:08<03:16,  1.40it/s, loss=0.596]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  71%|███████▏  | 668/937 [08:13<03:44,  1.20it/s, loss=0.619]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  68%|██████▊   | 641/937 [08:18<03:45,  1.32it/s, loss=0.0223]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  69%|██████▉   | 651/937 [08:24<03:34,  1.33it/s, loss=0.237]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  69%|██████▉   | 649/937 [08:28<03:57,  1.21it/s, loss=0.225]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  70%|███████   | 656/937 [08:33<03:47,  1.23it/s, loss=0.518]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  71%|███████   | 662/937 [08:38<03:47,  1.21it/s, loss=0.764]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  76%|███████▌  | 709/937 [08:43<02:56,  1.29it/s, loss=0.274] \u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  72%|███████▏  | 678/937 [08:49<03:34,  1.21it/s, loss=0.227]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  73%|███████▎  | 685/937 [08:54<03:06,  1.35it/s, loss=0.305] \u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  74%|███████▍  | 697/937 [09:00<02:50,  1.41it/s, loss=0.367] \u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  74%|███████▍  | 694/937 [09:04<03:33,  1.14it/s, loss=0.0259]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  80%|███████▉  | 745/937 [09:09<02:16,  1.41it/s, loss=0.0213]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  80%|████████  | 751/937 [09:14<02:43,  1.14it/s, loss=0.253]\u001b[32m [repeated 50x across cluster]\u001b[0m\nEpoch 1:  81%|████████  | 758/937 [09:19<02:03,  1.45it/s, loss=0.612]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  77%|███████▋  | 720/937 [09:25<03:04,  1.18it/s, loss=0.0671]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  78%|███████▊  | 730/937 [09:30<02:55,  1.18it/s, loss=0.0262]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  79%|███████▉  | 743/937 [09:35<02:48,  1.15it/s, loss=0.0172]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  80%|████████  | 750/937 [09:40<02:20,  1.33it/s, loss=0.0351]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  80%|███████▉  | 747/937 [09:45<02:20,  1.35it/s, loss=0.0303]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  81%|████████▏ | 763/937 [09:51<02:30,  1.16it/s, loss=0.0591]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  81%|████████  | 761/937 [09:55<02:07,  1.38it/s, loss=0.672]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  82%|████████▏ | 771/937 [10:00<02:01,  1.36it/s, loss=0.033]\u001b[32m [repeated 57x across cluster]\u001b[0m\nEpoch 1:  84%|████████▎ | 783/937 [10:06<01:52,  1.37it/s, loss=1.18]  \u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  84%|████████▎ | 784/937 [10:10<02:00,  1.27it/s, loss=0.203]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  84%|████████▍ | 790/937 [10:16<02:05,  1.17it/s, loss=0.0227]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  85%|████████▍ | 794/937 [10:20<01:49,  1.31it/s, loss=0.677]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  90%|█████████ | 847/937 [10:25<01:07,  1.34it/s, loss=0.548]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  86%|████████▋ | 810/937 [10:31<01:37,  1.31it/s, loss=0.0134]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  91%|█████████▏| 856/937 [10:32<00:59,  1.37it/s, loss=0.068]\nEpoch 1:  91%|█████████▏| 856/937 [10:32<00:59,  1.37it/s, loss=0.419]\nEpoch 1:  91%|█████████▏| 857/937 [10:33<00:56,  1.41it/s, loss=0.419]\nEpoch 1:  91%|█████████▏| 857/937 [10:33<00:56,  1.41it/s, loss=0.415]\nEpoch 1:  92%|█████████▏| 858/937 [10:33<00:55,  1.42it/s, loss=0.415]\nEpoch 1:  92%|█████████▏| 858/937 [10:34<00:55,  1.42it/s, loss=0.015]\nEpoch 1:  92%|█████████▏| 859/937 [10:34<00:54,  1.44it/s, loss=0.015]\nEpoch 1:  92%|█████████▏| 859/937 [10:34<00:54,  1.44it/s, loss=0.0682]\nEpoch 1:  92%|█████████▏| 860/937 [10:35<00:55,  1.39it/s, loss=0.0682]\nEpoch 1:  92%|█████████▏| 860/937 [10:35<00:55,  1.39it/s, loss=0.0934]\nEpoch 1:  87%|████████▋ | 813/937 [10:36<01:42,  1.21it/s, loss=0.299]\u001b[32m [repeated 44x across cluster]\u001b[0m\nEpoch 1:  92%|█████████▏| 861/937 [10:36<00:57,  1.31it/s, loss=0.0934]\nEpoch 1:  92%|█████████▏| 861/937 [10:36<00:57,  1.31it/s, loss=0.39]  \nEpoch 1:  92%|█████████▏| 862/937 [10:36<00:55,  1.36it/s, loss=0.39]\nEpoch 1:  92%|█████████▏| 862/937 [10:37<00:55,  1.36it/s, loss=0.039]\nEpoch 1:  92%|█████████▏| 863/937 [10:37<00:53,  1.39it/s, loss=0.039]\nEpoch 1:  92%|█████████▏| 863/937 [10:37<00:53,  1.39it/s, loss=0.339]\nEpoch 1:  92%|█████████▏| 864/937 [10:38<00:53,  1.37it/s, loss=0.339]\nEpoch 1:  92%|█████████▏| 864/937 [10:38<00:53,  1.37it/s, loss=0.434]\nEpoch 1:  92%|█████████▏| 865/937 [10:38<00:53,  1.34it/s, loss=0.434]\nEpoch 1:  92%|█████████▏| 865/937 [10:39<00:53,  1.34it/s, loss=0.297]\nEpoch 1:  92%|█████████▏| 866/937 [10:39<00:53,  1.32it/s, loss=0.297]\nEpoch 1:  92%|█████████▏| 866/937 [10:40<00:53,  1.32it/s, loss=0.0209]\nEpoch 1:  93%|█████████▎| 867/937 [10:40<00:49,  1.40it/s, loss=0.0209]\nEpoch 1:  93%|█████████▎| 867/937 [10:40<00:49,  1.40it/s, loss=0.0196]\nEpoch 1:  88%|████████▊ | 829/937 [10:41<01:30,  1.20it/s, loss=0.368]\u001b[32m [repeated 40x across cluster]\u001b[0m\nEpoch 1:  93%|█████████▎| 868/937 [10:41<00:50,  1.37it/s, loss=0.0196]\nEpoch 1:  93%|█████████▎| 868/937 [10:41<00:50,  1.37it/s, loss=1.27]  \nEpoch 1:  93%|█████████▎| 869/937 [10:41<00:50,  1.35it/s, loss=1.27]\nEpoch 1:  93%|█████████▎| 869/937 [10:42<00:50,  1.35it/s, loss=1.11]\nEpoch 1:  93%|█████████▎| 870/937 [10:42<00:47,  1.41it/s, loss=1.11]\nEpoch 1:  93%|█████████▎| 870/937 [10:42<00:47,  1.41it/s, loss=0.0111]\nEpoch 1:  93%|█████████▎| 871/937 [10:43<00:46,  1.42it/s, loss=0.0111]\nEpoch 1:  93%|█████████▎| 871/937 [10:43<00:46,  1.42it/s, loss=0.022] \nEpoch 1:  93%|█████████▎| 872/937 [10:43<00:46,  1.40it/s, loss=0.022]\nEpoch 1:  93%|█████████▎| 872/937 [10:44<00:46,  1.40it/s, loss=0.0115]\nEpoch 1:  93%|█████████▎| 873/937 [10:44<00:45,  1.41it/s, loss=0.0115]\nEpoch 1:  93%|█████████▎| 873/937 [10:44<00:45,  1.41it/s, loss=0.0156]\nEpoch 1:  93%|█████████▎| 874/937 [10:45<00:43,  1.45it/s, loss=0.0156]\nEpoch 1:  93%|█████████▎| 874/937 [10:45<00:43,  1.45it/s, loss=0.366] \nEpoch 1:  93%|█████████▎| 875/937 [10:45<00:42,  1.47it/s, loss=0.366]\nEpoch 1:  88%|████████▊ | 826/937 [10:46<01:28,  1.26it/s, loss=0.0147]\u001b[32m [repeated 39x across cluster]\u001b[0m\nEpoch 1:  93%|█████████▎| 875/937 [10:46<00:42,  1.47it/s, loss=0.457]\nEpoch 1:  93%|█████████▎| 876/937 [10:46<00:45,  1.35it/s, loss=0.457]\nEpoch 1:  93%|█████████▎| 876/937 [10:47<00:45,  1.35it/s, loss=1.04] \nEpoch 1:  94%|█████████▎| 877/937 [10:47<00:48,  1.25it/s, loss=1.04]\nEpoch 1:  94%|█████████▎| 877/937 [10:48<00:48,  1.25it/s, loss=0.537]\nEpoch 1:  94%|█████████▎| 878/937 [10:48<00:46,  1.26it/s, loss=0.537]\nEpoch 1:  94%|█████████▎| 878/937 [10:48<00:46,  1.26it/s, loss=0.0611]\nEpoch 1:  94%|█████████▍| 879/937 [10:49<00:44,  1.31it/s, loss=0.0611]\nEpoch 1:  94%|█████████▍| 879/937 [10:49<00:44,  1.31it/s, loss=0.574] \nEpoch 1:  94%|█████████▍| 880/937 [10:50<00:48,  1.18it/s, loss=0.574]\nEpoch 1:  94%|█████████▍| 880/937 [10:50<00:48,  1.18it/s, loss=0.432]\nEpoch 1:  94%|█████████▍| 881/937 [10:51<00:49,  1.13it/s, loss=0.432]\nEpoch 1:  89%|████████▉ | 832/937 [10:51<01:26,  1.21it/s, loss=0.289] \u001b[32m [repeated 39x across cluster]\u001b[0m\nEpoch 1:  94%|█████████▍| 881/937 [10:51<00:49,  1.13it/s, loss=1.31] \nEpoch 1:  94%|█████████▍| 882/937 [10:52<00:46,  1.19it/s, loss=1.31]\nEpoch 1:  94%|█████████▍| 882/937 [10:52<00:46,  1.19it/s, loss=0.17]\nEpoch 1:  94%|█████████▍| 883/937 [10:52<00:41,  1.29it/s, loss=0.17]\nEpoch 1:  94%|█████████▍| 883/937 [10:53<00:41,  1.29it/s, loss=0.448]\nEpoch 1:  94%|█████████▍| 884/937 [10:53<00:41,  1.29it/s, loss=0.448]\nEpoch 1:  94%|█████████▍| 884/937 [10:53<00:41,  1.29it/s, loss=1.49] \nEpoch 1:  94%|█████████▍| 885/937 [10:54<00:39,  1.31it/s, loss=1.49]\nEpoch 1:  94%|█████████▍| 885/937 [10:54<00:39,  1.31it/s, loss=0.268]\nEpoch 1:  95%|█████████▍| 886/937 [10:54<00:38,  1.34it/s, loss=0.268]\nEpoch 1:  95%|█████████▍| 886/937 [10:55<00:38,  1.34it/s, loss=0.0782]\nEpoch 1:  95%|█████████▍| 887/937 [10:55<00:36,  1.38it/s, loss=0.0782]\nEpoch 1:  95%|█████████▍| 887/937 [10:55<00:36,  1.38it/s, loss=0.043] \nEpoch 1:  95%|█████████▍| 888/937 [10:56<00:37,  1.32it/s, loss=0.043]\nEpoch 1:  91%|█████████ | 850/937 [10:57<01:03,  1.37it/s, loss=0.701]\u001b[32m [repeated 43x across cluster]\u001b[0m\nEpoch 1:  95%|█████████▍| 888/937 [10:56<00:37,  1.32it/s, loss=0.0842]\nEpoch 1:  95%|█████████▍| 889/937 [10:57<00:36,  1.30it/s, loss=0.0842]\nEpoch 1:  95%|█████████▍| 889/937 [10:57<00:36,  1.30it/s, loss=0.546] \nEpoch 1:  95%|█████████▍| 890/937 [10:57<00:35,  1.32it/s, loss=0.546]\nEpoch 1:  95%|█████████▍| 890/937 [10:58<00:35,  1.32it/s, loss=0.227]\nEpoch 1:  95%|█████████▌| 891/937 [10:58<00:35,  1.28it/s, loss=0.227]\nEpoch 1:  95%|█████████▌| 891/937 [10:58<00:35,  1.28it/s, loss=0.0194]\nEpoch 1:  95%|█████████▌| 892/937 [10:59<00:33,  1.35it/s, loss=0.0194]\nEpoch 1:  95%|█████████▌| 892/937 [10:59<00:33,  1.35it/s, loss=0.971] \nEpoch 1:  95%|█████████▌| 893/937 [11:00<00:31,  1.41it/s, loss=0.971]\nEpoch 1:  95%|█████████▌| 893/937 [11:00<00:31,  1.41it/s, loss=0.641]\nEpoch 1:  95%|█████████▌| 894/937 [11:00<00:30,  1.40it/s, loss=0.641]\nEpoch 1:  95%|█████████▌| 894/937 [11:01<00:30,  1.40it/s, loss=0.31] \nEpoch 1:  91%|█████████ | 850/937 [11:01<01:15,  1.15it/s, loss=0.211]\u001b[32m [repeated 35x across cluster]\u001b[0m\nEpoch 1:  92%|█████████▏| 859/937 [11:04<01:02,  1.25it/s, loss=0.301]\u001b[32m [repeated 14x across cluster]\u001b[0m\nEpoch 1:  91%|█████████ | 851/937 [11:06<01:13,  1.18it/s, loss=0.0225]\u001b[32m [repeated 23x across cluster]\u001b[0m\nEpoch 1:  97%|█████████▋| 905/937 [11:08<00:24,  1.32it/s, loss=0.0257]\u001b[32m [repeated 36x across cluster]\u001b[0m\nEpoch 1:  91%|█████████ | 855/937 [11:09<01:03,  1.28it/s, loss=0.023]\u001b[32m [repeated 8x across cluster]\u001b[0m\nEpoch 1:  97%|█████████▋| 912/937 [11:14<00:17,  1.43it/s, loss=0.0463]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  93%|█████████▎| 867/937 [11:19<01:01,  1.14it/s, loss=0.0172]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  93%|█████████▎| 873/937 [11:24<00:56,  1.14it/s, loss=0.461]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  94%|█████████▍| 880/937 [11:29<00:43,  1.30it/s, loss=0.0243]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1: 100%|██████████| 937/937 [11:32<00:00,  1.35it/s, loss=0.0129]\nEpoch 1:  96%|█████████▌| 897/937 [11:35<00:30,  1.31it/s, loss=0.36] \u001b[32m [repeated 46x across cluster]\u001b[0m\nEpoch 1:  96%|█████████▌| 898/937 [11:39<00:28,  1.35it/s, loss=0.0723]\u001b[32m [repeated 41x across cluster]\u001b[0m\nEpoch 1:  96%|█████████▌| 901/937 [11:44<00:27,  1.31it/s, loss=0.0145]\u001b[32m [repeated 44x across cluster]\u001b[0m\nEpoch 1:  98%|█████████▊| 918/937 [11:50<00:12,  1.53it/s, loss=0.421]\u001b[32m [repeated 42x across cluster]\u001b[0m\nEpoch 1:  98%|█████████▊| 916/937 [11:55<00:14,  1.43it/s, loss=1.22]\u001b[32m [repeated 42x across cluster]\u001b[0m\nEpoch 1:  99%|█████████▉| 932/937 [12:00<00:03,  1.30it/s, loss=0.0559]\u001b[32m [repeated 45x across cluster]\u001b[0m\nEpoch 1: 100%|██████████| 937/937 [12:04<00:00,  1.29it/s, loss=0.037]\nEpoch 1:  99%|█████████▉| 931/937 [12:05<00:04,  1.45it/s, loss=0.475]\u001b[32m [repeated 37x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n\u001b[36m(ClientAppActor pid=658)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=658)\u001b[0m \n\u001b[36m(ClientAppActor pid=658)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=658)\u001b[0m             entirely in future versions of Flower.\n\u001b[36m(ClientAppActor pid=658)\u001b[0m         \nEpoch 1: 100%|██████████| 937/937 [12:08<00:00,  1.29it/s, loss=0.942]\u001b[32m [repeated 2x across cluster]\u001b[0m\nEpoch 1: 100%|█████████▉| 936/937 [12:08<00:00,  1.56it/s, loss=0.942]\u001b[32m [repeated 17x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=657)\u001b[0m \n\u001b[36m(ClientAppActor pid=657)\u001b[0m         \n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=658)\u001b[0m Total HuBERT layers: 12\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=655)\u001b[0m \n\u001b[36m(ClientAppActor pid=655)\u001b[0m         \n\u001b[36m(ClientAppActor pid=697)\u001b[0m \n\u001b[36m(ClientAppActor pid=697)\u001b[0m         \n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 2]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n\u001b[36m(ClientAppActor pid=657)\u001b[0m \n\u001b[36m(ClientAppActor pid=657)\u001b[0m         \n\u001b[36m(ClientAppActor pid=657)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=657)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=657)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=658)\u001b[0m \n\u001b[36m(ClientAppActor pid=658)\u001b[0m         \n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=657)\u001b[0m Total HuBERT layers: 12\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=655)\u001b[0m \n\u001b[36m(ClientAppActor pid=655)\u001b[0m         \n\u001b[36m(ClientAppActor pid=697)\u001b[0m \n\u001b[36m(ClientAppActor pid=697)\u001b[0m         \nEpoch 1:   0%|          | 0/937 [00:00<?, ?it/s]\nEpoch 1:   0%|          | 0/937 [00:00<?, ?it/s, loss=0.698]\nEpoch 1:   0%|          | 1/937 [00:01<28:13,  1.81s/it, loss=0.698]\n\u001b[36m(ClientAppActor pid=697)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=697)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=697)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   0%|          | 1/937 [00:02<28:13,  1.81s/it, loss=0.0298]\nEpoch 1:   0%|          | 0/937 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   0%|          | 0/937 [00:00<?, ?it/s, loss=0.0127]\u001b[32m [repeated 3x across cluster]\u001b[0m\nEpoch 1:   1%|          | 6/937 [00:05<12:56,  1.20it/s, loss=0.00965]\u001b[32m [repeated 40x across cluster]\u001b[0m\nEpoch 1:   1%|▏         | 12/937 [00:10<12:30,  1.23it/s, loss=1.02]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   2%|▏         | 20/937 [00:16<10:54,  1.40it/s, loss=0.0257]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   3%|▎         | 27/937 [00:21<11:14,  1.35it/s, loss=0.0147]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:   4%|▎         | 33/937 [00:27<11:21,  1.33it/s, loss=0.00727]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:   4%|▍         | 39/937 [00:32<11:08,  1.34it/s, loss=0.00874]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:   5%|▍         | 45/937 [00:37<12:27,  1.19it/s, loss=0.0136] \u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:   5%|▌         | 51/937 [00:41<11:42,  1.26it/s, loss=0.011]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   6%|▋         | 59/937 [00:47<10:48,  1.35it/s, loss=0.0349]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   7%|▋         | 65/937 [00:52<11:37,  1.25it/s, loss=0.0451]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:   8%|▊         | 73/937 [00:56<11:17,  1.27it/s, loss=0.0585]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   8%|▊         | 79/937 [01:02<11:18,  1.26it/s, loss=0.0145]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:   9%|▉         | 82/937 [01:06<12:10,  1.17it/s, loss=0.0566]\u001b[32m [repeated 49x across cluster]\u001b[0m\nEpoch 1:  10%|▉         | 91/937 [01:13<12:11,  1.16it/s, loss=0.0128]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  10%|█         | 95/937 [01:16<10:37,  1.32it/s, loss=0.812]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  12%|█▏        | 108/937 [01:20<10:08,  1.36it/s, loss=0.701]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  12%|█▏        | 112/937 [01:27<10:37,  1.29it/s, loss=0.253]\u001b[32m [repeated 54x across cluster]\u001b[0m\nEpoch 1:  12%|█▏        | 115/937 [01:32<09:57,  1.38it/s, loss=0.0299]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  13%|█▎        | 125/937 [01:37<11:03,  1.22it/s, loss=0.0761]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  14%|█▎        | 128/937 [01:42<11:27,  1.18it/s, loss=1.23] \u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  15%|█▌        | 143/937 [01:46<09:21,  1.41it/s, loss=0.0213]\u001b[32m [repeated 52x across cluster]\u001b[0m\nEpoch 1:  15%|█▌        | 141/937 [01:54<10:30,  1.26it/s, loss=1.4]   \u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  16%|█▌        | 151/937 [01:58<09:53,  1.32it/s, loss=0.0272] \u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  17%|█▋        | 158/937 [02:03<10:31,  1.23it/s, loss=0.39]\u001b[32m [repeated 55x across cluster]\u001b[0m\nEpoch 1:  18%|█▊        | 164/937 [02:08<11:19,  1.14it/s, loss=0.672]\u001b[32m [repeated 48x across cluster]\u001b[0m\nEpoch 1:  18%|█▊        | 166/937 [02:13<10:13,  1.26it/s, loss=0.585]\u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  19%|█▉        | 177/937 [02:18<09:49,  1.29it/s, loss=0.011]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  19%|█▉        | 178/937 [02:23<10:07,  1.25it/s, loss=0.164] \u001b[32m [repeated 51x across cluster]\u001b[0m\nEpoch 1:  20%|██        | 189/937 [02:29<10:14,  1.22it/s, loss=0.078]\u001b[32m [repeated 53x across cluster]\u001b[0m\nEpoch 1:  20%|██        | 192/937 [02:33<09:08,  1.36it/s, loss=0.655]\u001b[32m [repeated 56x across cluster]\u001b[0m\nEpoch 1:  22%|██▏       | 202/937 [02:39<09:56,  1.23it/s, loss=0.255]\u001b[32m [repeated 52x across cluster]\u001b[0m\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# # Access metrics directly\n# all_metrics = ray.get(metrics_collector.metrics.remote())\n\n# # Plot specific round\n# ray.get(metrics_collector.plot_round_metrics.remote(3))  # Plot round 3\n\n# # Plot client 0's progress\n# ray.get(metrics_collector.plot_client_progress.remote(0))\n# # Load parameters from round 5\n\n# params = torch.load(\"round_5_params.pth\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-07T01:24:01.958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ray.shutdown()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-07T01:24:01.958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# m=DiskMetricsCollector()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-07T01:24:01.958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}